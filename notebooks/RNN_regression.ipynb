{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8854d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Path (/Users/rik/Documents/VU/DMT/DataMiningTechniquesA1) already exists in sys.path\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run ./initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1e819f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_loading import DataPreprocessor\n",
    "from mood_RNN_regression import RNNRegressor, MoodDataset, objective, train_epoch, train_final_model, evaluate, predict, plot_mood_predictions\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05db5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 24 outliers from 1002 observations. Percentage: 2.40%\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataPreprocessor()\n",
    "train_df_split, val_df_split, pred_df = data_loader.load_and_preprocess_data(\"1d\", 0.5, 1, do_bucketing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afb48efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume train_df and test_df are loaded and preprocessed\n",
    "id_map = {id_: idx for idx, id_ in enumerate(train_df_split['id'].unique())}\n",
    "input_dim = train_df_split.drop(columns=['id', 'mood', 'date']).shape[1]\n",
    "id_count = len(id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ce2752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 16:26:24,827] A new study created in memory with name: no-name-21d1af6c-32bd-4898-ad07-a5fe25ca32b5\n",
      "[I 2025-04-19 16:26:24,989] Trial 0 finished with value: 7.140174749202298 and parameters: {'hidden_dim': 127, 'id_embed_dim': 7, 'lr': 0.0016091204432181034, 'batch_size': 128}. Best is trial 0 with value: 7.140174749202298.\n",
      "[I 2025-04-19 16:26:25,130] Trial 1 finished with value: 49.02159732445738 and parameters: {'hidden_dim': 67, 'id_embed_dim': 14, 'lr': 0.00013052116691146347, 'batch_size': 128}. Best is trial 0 with value: 7.140174749202298.\n",
      "[I 2025-04-19 16:26:25,255] Trial 2 finished with value: 6.821395796940739 and parameters: {'hidden_dim': 72, 'id_embed_dim': 12, 'lr': 0.00181194643219288, 'batch_size': 128}. Best is trial 2 with value: 6.821395796940739.\n",
      "[I 2025-04-19 16:26:25,538] Trial 3 finished with value: 34.40096767683674 and parameters: {'hidden_dim': 125, 'id_embed_dim': 9, 'lr': 0.00016556532080063723, 'batch_size': 32}. Best is trial 2 with value: 6.821395796940739.\n",
      "[I 2025-04-19 16:26:25,673] Trial 4 finished with value: 0.5850018733426144 and parameters: {'hidden_dim': 99, 'id_embed_dim': 14, 'lr': 0.008375640474528458, 'batch_size': 128}. Best is trial 4 with value: 0.5850018733426144.\n",
      "[I 2025-04-19 16:26:25,872] Trial 5 finished with value: 1.4961518273317724 and parameters: {'hidden_dim': 67, 'id_embed_dim': 16, 'lr': 0.0022508157060941027, 'batch_size': 64}. Best is trial 4 with value: 0.5850018733426144.\n",
      "[I 2025-04-19 16:26:26,091] Trial 6 finished with value: 4.029973349176851 and parameters: {'hidden_dim': 63, 'id_embed_dim': 15, 'lr': 0.0006221803579767036, 'batch_size': 32}. Best is trial 4 with value: 0.5850018733426144.\n",
      "[I 2025-04-19 16:26:26,276] Trial 7 finished with value: 0.8923621858869281 and parameters: {'hidden_dim': 116, 'id_embed_dim': 6, 'lr': 0.00800017888841833, 'batch_size': 64}. Best is trial 4 with value: 0.5850018733426144.\n",
      "[I 2025-04-19 16:26:26,398] Trial 8 finished with value: 21.762957565766527 and parameters: {'hidden_dim': 64, 'id_embed_dim': 15, 'lr': 0.0009938070390818877, 'batch_size': 128}. Best is trial 4 with value: 0.5850018733426144.\n",
      "[I 2025-04-19 16:26:26,676] Trial 9 finished with value: 5.57769911629813 and parameters: {'hidden_dim': 104, 'id_embed_dim': 7, 'lr': 0.0005351595698195747, 'batch_size': 32}. Best is trial 4 with value: 0.5850018733426144.\n",
      "[I 2025-04-19 16:26:26,804] Trial 10 finished with value: 1.0786315646386684 and parameters: {'hidden_dim': 35, 'id_embed_dim': 11, 'lr': 0.008205829517981685, 'batch_size': 128}. Best is trial 4 with value: 0.5850018733426144.\n",
      "[I 2025-04-19 16:26:26,981] Trial 11 finished with value: 0.8583324349912486 and parameters: {'hidden_dim': 99, 'id_embed_dim': 4, 'lr': 0.009407906584213609, 'batch_size': 64}. Best is trial 4 with value: 0.5850018733426144.\n",
      "[I 2025-04-19 16:26:27,158] Trial 12 finished with value: 1.1607008446428113 and parameters: {'hidden_dim': 92, 'id_embed_dim': 4, 'lr': 0.004169431842286695, 'batch_size': 64}. Best is trial 4 with value: 0.5850018733426144.\n",
      "[I 2025-04-19 16:26:27,336] Trial 13 finished with value: 0.5604350029077745 and parameters: {'hidden_dim': 87, 'id_embed_dim': 13, 'lr': 0.004406901740052123, 'batch_size': 64}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:27,518] Trial 14 finished with value: 0.5712584526018989 and parameters: {'hidden_dim': 87, 'id_embed_dim': 13, 'lr': 0.0036081308783153807, 'batch_size': 64}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:27,706] Trial 15 finished with value: 0.7187014235589737 and parameters: {'hidden_dim': 83, 'id_embed_dim': 12, 'lr': 0.003766466970521845, 'batch_size': 64}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:27,874] Trial 16 finished with value: 0.885383559348888 and parameters: {'hidden_dim': 83, 'id_embed_dim': 10, 'lr': 0.004134827999583286, 'batch_size': 64}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:28,032] Trial 17 finished with value: 1.391270431360804 and parameters: {'hidden_dim': 49, 'id_embed_dim': 13, 'lr': 0.002810089945543038, 'batch_size': 64}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:28,209] Trial 18 finished with value: 3.5242165676633217 and parameters: {'hidden_dim': 114, 'id_embed_dim': 9, 'lr': 0.001108645251488056, 'batch_size': 64}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:28,379] Trial 19 finished with value: 39.569711842931305 and parameters: {'hidden_dim': 88, 'id_embed_dim': 12, 'lr': 0.00024925193989014795, 'batch_size': 64}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:28,556] Trial 20 finished with value: 0.6239144394272252 and parameters: {'hidden_dim': 78, 'id_embed_dim': 16, 'lr': 0.0046948847040841945, 'batch_size': 64}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:28,696] Trial 21 finished with value: 0.8855173838765997 and parameters: {'hidden_dim': 96, 'id_embed_dim': 14, 'lr': 0.005814592671241685, 'batch_size': 128}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:28,839] Trial 22 finished with value: 1.9655313671083379 and parameters: {'hidden_dim': 105, 'id_embed_dim': 13, 'lr': 0.0027954132287878464, 'batch_size': 128}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:29,094] Trial 23 finished with value: 0.6680550611108765 and parameters: {'hidden_dim': 109, 'id_embed_dim': 14, 'lr': 0.006503224214636534, 'batch_size': 32}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:29,275] Trial 24 finished with value: 0.6578756875561592 and parameters: {'hidden_dim': 91, 'id_embed_dim': 11, 'lr': 0.005644317602417641, 'batch_size': 64}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:29,408] Trial 25 finished with value: 0.6150118869946415 and parameters: {'hidden_dim': 75, 'id_embed_dim': 13, 'lr': 0.009897329006682245, 'batch_size': 128}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:29,565] Trial 26 finished with value: 0.6731474121710411 and parameters: {'hidden_dim': 56, 'id_embed_dim': 15, 'lr': 0.00297321664737957, 'batch_size': 64}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:29,737] Trial 27 finished with value: 1.6902068898193818 and parameters: {'hidden_dim': 98, 'id_embed_dim': 11, 'lr': 0.0012992954094570538, 'batch_size': 64}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:29,983] Trial 28 finished with value: 0.6030035753895465 and parameters: {'hidden_dim': 86, 'id_embed_dim': 13, 'lr': 0.0058984847103813265, 'batch_size': 32}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:30,129] Trial 29 finished with value: 5.403593622652211 and parameters: {'hidden_dim': 113, 'id_embed_dim': 10, 'lr': 0.0017208142145337662, 'batch_size': 128}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:30,272] Trial 30 finished with value: 1.3145900202873058 and parameters: {'hidden_dim': 103, 'id_embed_dim': 14, 'lr': 0.0033056457175708156, 'batch_size': 128}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:30,510] Trial 31 finished with value: 0.6216967796024523 and parameters: {'hidden_dim': 85, 'id_embed_dim': 13, 'lr': 0.006270081615145438, 'batch_size': 32}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:30,750] Trial 32 finished with value: 0.6024060419627598 and parameters: {'hidden_dim': 92, 'id_embed_dim': 12, 'lr': 0.005236546978682834, 'batch_size': 32}. Best is trial 13 with value: 0.5604350029077745.\n",
      "[I 2025-04-19 16:26:30,992] Trial 33 finished with value: 0.5485353138213768 and parameters: {'hidden_dim': 93, 'id_embed_dim': 12, 'lr': 0.002077932908311164, 'batch_size': 32}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:31,257] Trial 34 finished with value: 0.7421908952239761 and parameters: {'hidden_dim': 121, 'id_embed_dim': 15, 'lr': 0.002216301095599589, 'batch_size': 32}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:31,484] Trial 35 finished with value: 0.6186179290140482 and parameters: {'hidden_dim': 74, 'id_embed_dim': 12, 'lr': 0.002103385857604641, 'batch_size': 32}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:31,623] Trial 36 finished with value: 8.91503886262277 and parameters: {'hidden_dim': 95, 'id_embed_dim': 14, 'lr': 0.0015624937752345093, 'batch_size': 128}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:31,843] Trial 37 finished with value: 3.6730551612108275 and parameters: {'hidden_dim': 71, 'id_embed_dim': 9, 'lr': 0.0007149649387132681, 'batch_size': 32}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:32,012] Trial 38 finished with value: 1.0138832034921288 and parameters: {'hidden_dim': 79, 'id_embed_dim': 11, 'lr': 0.002426509873988253, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:32,151] Trial 39 finished with value: 0.654488970462541 and parameters: {'hidden_dim': 101, 'id_embed_dim': 16, 'lr': 0.007420612400092757, 'batch_size': 128}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:32,410] Trial 40 finished with value: 7.0895796467487076 and parameters: {'hidden_dim': 108, 'id_embed_dim': 14, 'lr': 0.0003645482698472755, 'batch_size': 32}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:32,651] Trial 41 finished with value: 0.6041964664495081 and parameters: {'hidden_dim': 92, 'id_embed_dim': 12, 'lr': 0.00476107464742769, 'batch_size': 32}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:32,902] Trial 42 finished with value: 0.7303768638381385 and parameters: {'hidden_dim': 89, 'id_embed_dim': 13, 'lr': 0.00352964605303417, 'batch_size': 32}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:33,140] Trial 43 finished with value: 0.6642446894394723 and parameters: {'hidden_dim': 95, 'id_embed_dim': 11, 'lr': 0.004868315866367147, 'batch_size': 32}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:33,365] Trial 44 finished with value: 0.5978366849117709 and parameters: {'hidden_dim': 80, 'id_embed_dim': 12, 'lr': 0.007750805109778893, 'batch_size': 32}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:33,523] Trial 45 finished with value: 0.6407526077184462 and parameters: {'hidden_dim': 68, 'id_embed_dim': 15, 'lr': 0.00845958821912933, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:33,749] Trial 46 finished with value: 41.27709020170054 and parameters: {'hidden_dim': 80, 'id_embed_dim': 12, 'lr': 0.00012068734613497538, 'batch_size': 32}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:33,871] Trial 47 finished with value: 1.5980764923239112 and parameters: {'hidden_dim': 59, 'id_embed_dim': 10, 'lr': 0.0037532247212245834, 'batch_size': 128}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:34,034] Trial 48 finished with value: 0.6459206952188248 and parameters: {'hidden_dim': 85, 'id_embed_dim': 9, 'lr': 0.009830893426775752, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:34,218] Trial 49 finished with value: 0.5783712648807612 and parameters: {'hidden_dim': 128, 'id_embed_dim': 13, 'lr': 0.007066228919086579, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:34,403] Trial 50 finished with value: 0.6357727463084056 and parameters: {'hidden_dim': 118, 'id_embed_dim': 13, 'lr': 0.0071376993042849435, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:34,589] Trial 51 finished with value: 0.5979884387855243 and parameters: {'hidden_dim': 126, 'id_embed_dim': 14, 'lr': 0.007632090539310249, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:34,751] Trial 52 finished with value: 0.6915104510192585 and parameters: {'hidden_dim': 76, 'id_embed_dim': 13, 'lr': 0.004168608051211621, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:34,901] Trial 53 finished with value: 0.612912508778106 and parameters: {'hidden_dim': 33, 'id_embed_dim': 15, 'lr': 0.008379194935544239, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:35,071] Trial 54 finished with value: 0.552422304798786 and parameters: {'hidden_dim': 81, 'id_embed_dim': 12, 'lr': 0.00654904020060761, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:35,256] Trial 55 finished with value: 0.6873541756680137 and parameters: {'hidden_dim': 121, 'id_embed_dim': 14, 'lr': 0.003128842748382088, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:35,432] Trial 56 finished with value: 0.9286612621823648 and parameters: {'hidden_dim': 108, 'id_embed_dim': 11, 'lr': 0.004307307639331314, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:35,606] Trial 57 finished with value: 0.8947734420460866 and parameters: {'hidden_dim': 99, 'id_embed_dim': 7, 'lr': 0.006359034050079288, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:35,778] Trial 58 finished with value: 0.7941409663150185 and parameters: {'hidden_dim': 83, 'id_embed_dim': 12, 'lr': 0.0024795427897135037, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:35,964] Trial 59 finished with value: 5.636987876175041 and parameters: {'hidden_dim': 128, 'id_embed_dim': 6, 'lr': 0.000871475525011534, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:36,144] Trial 60 finished with value: 0.6408281774449169 and parameters: {'hidden_dim': 89, 'id_embed_dim': 13, 'lr': 0.005359722998771918, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:36,273] Trial 61 finished with value: 0.7689923527545499 and parameters: {'hidden_dim': 71, 'id_embed_dim': 12, 'lr': 0.0069576749369701365, 'batch_size': 128}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:36,443] Trial 62 finished with value: 43.985792489876424 and parameters: {'hidden_dim': 81, 'id_embed_dim': 11, 'lr': 0.0001713781242073066, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:36,687] Trial 63 finished with value: 0.6695748303169594 and parameters: {'hidden_dim': 87, 'id_embed_dim': 13, 'lr': 0.008975435947281934, 'batch_size': 32}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:36,858] Trial 64 finished with value: 0.5798292451335075 and parameters: {'hidden_dim': 94, 'id_embed_dim': 14, 'lr': 0.005403127146426663, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:37,031] Trial 65 finished with value: 0.7322517696179842 and parameters: {'hidden_dim': 96, 'id_embed_dim': 14, 'lr': 0.003762452060936201, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:37,203] Trial 66 finished with value: 0.59149482196435 and parameters: {'hidden_dim': 104, 'id_embed_dim': 16, 'lr': 0.005628645193171823, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:37,375] Trial 67 finished with value: 1.33881129716572 and parameters: {'hidden_dim': 94, 'id_embed_dim': 15, 'lr': 0.0013771241936492533, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:37,525] Trial 68 finished with value: 2.089933345192357 and parameters: {'hidden_dim': 39, 'id_embed_dim': 14, 'lr': 0.0019453253947903748, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:37,661] Trial 69 finished with value: 2.3147852985482467 and parameters: {'hidden_dim': 90, 'id_embed_dim': 15, 'lr': 0.0026921472789052164, 'batch_size': 128}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:37,839] Trial 70 finished with value: 0.6340177937557823 and parameters: {'hidden_dim': 111, 'id_embed_dim': 13, 'lr': 0.004528602588369195, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:38,016] Trial 71 finished with value: 0.6240470292872953 and parameters: {'hidden_dim': 106, 'id_embed_dim': 16, 'lr': 0.005528732799787385, 'batch_size': 64}. Best is trial 33 with value: 0.5485353138213768.\n",
      "[I 2025-04-19 16:26:38,193] Trial 72 finished with value: 0.5097200753993558 and parameters: {'hidden_dim': 99, 'id_embed_dim': 16, 'lr': 0.0062083876911516594, 'batch_size': 64}. Best is trial 72 with value: 0.5097200753993558.\n",
      "[I 2025-04-19 16:26:38,368] Trial 73 finished with value: 0.5059609511741122 and parameters: {'hidden_dim': 101, 'id_embed_dim': 15, 'lr': 0.006641930126102326, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:38,544] Trial 74 finished with value: 0.9107512836169479 and parameters: {'hidden_dim': 99, 'id_embed_dim': 16, 'lr': 0.006579707434392937, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:38,725] Trial 75 finished with value: 0.5241636947581643 and parameters: {'hidden_dim': 92, 'id_embed_dim': 15, 'lr': 0.0049518904431360726, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:38,895] Trial 76 finished with value: 0.5336301958650574 and parameters: {'hidden_dim': 102, 'id_embed_dim': 15, 'lr': 0.004086801519044525, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:39,060] Trial 77 finished with value: 0.528865060860053 and parameters: {'hidden_dim': 103, 'id_embed_dim': 15, 'lr': 0.0033329421136935305, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:39,231] Trial 78 finished with value: 0.7150634876767495 and parameters: {'hidden_dim': 102, 'id_embed_dim': 16, 'lr': 0.0033649656768808744, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:39,405] Trial 79 finished with value: 0.6433393256108564 and parameters: {'hidden_dim': 101, 'id_embed_dim': 15, 'lr': 0.004773250319980971, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:39,577] Trial 80 finished with value: 0.7749620783597904 and parameters: {'hidden_dim': 98, 'id_embed_dim': 15, 'lr': 0.004077452929897891, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:39,804] Trial 81 finished with value: 0.7447652198318252 and parameters: {'hidden_dim': 106, 'id_embed_dim': 16, 'lr': 0.0030149985164320665, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:39,977] Trial 82 finished with value: 0.676383564346715 and parameters: {'hidden_dim': 84, 'id_embed_dim': 15, 'lr': 0.002644993323477265, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:40,154] Trial 83 finished with value: 0.6366235214964788 and parameters: {'hidden_dim': 92, 'id_embed_dim': 16, 'lr': 0.003534469371187181, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:40,335] Trial 84 finished with value: 0.8322075748802128 and parameters: {'hidden_dim': 87, 'id_embed_dim': 15, 'lr': 0.004745966506129089, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:40,517] Trial 85 finished with value: 0.5569868240141331 and parameters: {'hidden_dim': 97, 'id_embed_dim': 14, 'lr': 0.003988673566715372, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:40,690] Trial 86 finished with value: 0.5682561065917625 and parameters: {'hidden_dim': 96, 'id_embed_dim': 15, 'lr': 0.003969808683095042, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:40,869] Trial 87 finished with value: 0.6055607777789123 and parameters: {'hidden_dim': 101, 'id_embed_dim': 14, 'lr': 0.006327588649930203, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:41,048] Trial 88 finished with value: 0.5414699118836481 and parameters: {'hidden_dim': 110, 'id_embed_dim': 16, 'lr': 0.005142326720464829, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:41,231] Trial 89 finished with value: 0.8349194777639288 and parameters: {'hidden_dim': 111, 'id_embed_dim': 8, 'lr': 0.005072953970251753, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:41,414] Trial 90 finished with value: 0.5195543102751997 and parameters: {'hidden_dim': 115, 'id_embed_dim': 16, 'lr': 0.0031666043084861793, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:41,596] Trial 91 finished with value: 0.9801765635497588 and parameters: {'hidden_dim': 114, 'id_embed_dim': 16, 'lr': 0.0031265281012481734, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:41,778] Trial 92 finished with value: 0.6714036859067759 and parameters: {'hidden_dim': 110, 'id_embed_dim': 16, 'lr': 0.002286696800419696, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:41,959] Trial 93 finished with value: 0.5715104350470063 and parameters: {'hidden_dim': 116, 'id_embed_dim': 16, 'lr': 0.0059611126717480445, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:42,141] Trial 94 finished with value: 0.6169449816969105 and parameters: {'hidden_dim': 106, 'id_embed_dim': 15, 'lr': 0.00431030108677346, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:42,316] Trial 95 finished with value: 0.6653985762058344 and parameters: {'hidden_dim': 103, 'id_embed_dim': 15, 'lr': 0.0019614641848677253, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:42,492] Trial 96 finished with value: 0.7343349922868542 and parameters: {'hidden_dim': 108, 'id_embed_dim': 16, 'lr': 0.00342031322404213, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:42,677] Trial 97 finished with value: 23.273732952605513 and parameters: {'hidden_dim': 113, 'id_embed_dim': 15, 'lr': 0.00041510693768661563, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:42,854] Trial 98 finished with value: 0.5409152023774341 and parameters: {'hidden_dim': 123, 'id_embed_dim': 16, 'lr': 0.0038370947666268684, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:43,132] Trial 99 finished with value: 0.5460086756182793 and parameters: {'hidden_dim': 122, 'id_embed_dim': 16, 'lr': 0.0050377973956612695, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:43,398] Trial 100 finished with value: 0.5698880019940828 and parameters: {'hidden_dim': 123, 'id_embed_dim': 16, 'lr': 0.0029084545715296743, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:43,653] Trial 101 finished with value: 0.5529773755181104 and parameters: {'hidden_dim': 118, 'id_embed_dim': 16, 'lr': 0.005174142792623787, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:43,914] Trial 102 finished with value: 0.561214450158571 and parameters: {'hidden_dim': 124, 'id_embed_dim': 16, 'lr': 0.0059190774857087874, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:44,176] Trial 103 finished with value: 0.6753654990877423 and parameters: {'hidden_dim': 118, 'id_embed_dim': 16, 'lr': 0.007776549876597695, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:44,434] Trial 104 finished with value: 0.709264145757919 and parameters: {'hidden_dim': 122, 'id_embed_dim': 15, 'lr': 0.004395913821377463, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:44,609] Trial 105 finished with value: 0.604122689792088 and parameters: {'hidden_dim': 120, 'id_embed_dim': 16, 'lr': 0.008672812377742515, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:44,788] Trial 106 finished with value: 0.5662626973668435 and parameters: {'hidden_dim': 116, 'id_embed_dim': 15, 'lr': 0.007054648624871472, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:45,039] Trial 107 finished with value: 0.8453389961916701 and parameters: {'hidden_dim': 100, 'id_embed_dim': 5, 'lr': 0.003721316373109071, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:45,228] Trial 108 finished with value: 0.8237372520274686 and parameters: {'hidden_dim': 125, 'id_embed_dim': 10, 'lr': 0.00509247061124292, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:45,418] Trial 109 finished with value: 0.9355648209277848 and parameters: {'hidden_dim': 112, 'id_embed_dim': 8, 'lr': 0.006486103565520186, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:45,603] Trial 110 finished with value: 0.9875795460285101 and parameters: {'hidden_dim': 114, 'id_embed_dim': 15, 'lr': 0.0016538895778164162, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:45,867] Trial 111 finished with value: 0.6427645378543022 and parameters: {'hidden_dim': 117, 'id_embed_dim': 16, 'lr': 0.005255545477453463, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:46,126] Trial 112 finished with value: 0.5713853692649898 and parameters: {'hidden_dim': 120, 'id_embed_dim': 16, 'lr': 0.004697468195163528, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:46,390] Trial 113 finished with value: 0.585679893206833 and parameters: {'hidden_dim': 119, 'id_embed_dim': 16, 'lr': 0.0056433897628449395, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:46,649] Trial 114 finished with value: 0.5446273895134603 and parameters: {'hidden_dim': 108, 'id_embed_dim': 15, 'lr': 0.004432279911770235, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:46,893] Trial 115 finished with value: 0.6936679594498828 and parameters: {'hidden_dim': 105, 'id_embed_dim': 15, 'lr': 0.00326988270024846, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:47,146] Trial 116 finished with value: 0.5802309548944459 and parameters: {'hidden_dim': 108, 'id_embed_dim': 15, 'lr': 0.003929789713388533, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:47,325] Trial 117 finished with value: 0.8168490972734035 and parameters: {'hidden_dim': 103, 'id_embed_dim': 14, 'lr': 0.0045044932380002576, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:47,507] Trial 118 finished with value: 0.5706990858665982 and parameters: {'hidden_dim': 109, 'id_embed_dim': 16, 'lr': 0.0061363081294345525, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:47,686] Trial 119 finished with value: 0.5933625662237182 and parameters: {'hidden_dim': 105, 'id_embed_dim': 15, 'lr': 0.002578434648282448, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:47,947] Trial 120 finished with value: 1.0054683622561003 and parameters: {'hidden_dim': 98, 'id_embed_dim': 14, 'lr': 0.001001184764674925, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:48,180] Trial 121 finished with value: 0.5594133035580915 and parameters: {'hidden_dim': 93, 'id_embed_dim': 16, 'lr': 0.005111887257842815, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:48,437] Trial 122 finished with value: 0.6381044871825025 and parameters: {'hidden_dim': 116, 'id_embed_dim': 16, 'lr': 0.0036587218650090693, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:48,724] Trial 123 finished with value: 0.6411812377155275 and parameters: {'hidden_dim': 126, 'id_embed_dim': 15, 'lr': 0.006921079070361183, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:49,024] Trial 124 finished with value: 0.5997159570679629 and parameters: {'hidden_dim': 114, 'id_embed_dim': 16, 'lr': 0.004388472433090774, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:49,294] Trial 125 finished with value: 0.7047580641911442 and parameters: {'hidden_dim': 107, 'id_embed_dim': 15, 'lr': 0.00799211904382866, 'batch_size': 32}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:49,470] Trial 126 finished with value: 0.53314233005495 and parameters: {'hidden_dim': 102, 'id_embed_dim': 16, 'lr': 0.005742323170965602, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:49,648] Trial 127 finished with value: 0.6302655406464311 and parameters: {'hidden_dim': 102, 'id_embed_dim': 16, 'lr': 0.005646670452860244, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:49,828] Trial 128 finished with value: 0.6337894514987343 and parameters: {'hidden_dim': 100, 'id_embed_dim': 15, 'lr': 0.0040474100907965434, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:50,000] Trial 129 finished with value: 0.6423441933509999 and parameters: {'hidden_dim': 104, 'id_embed_dim': 15, 'lr': 0.002805227630855977, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:50,180] Trial 130 finished with value: 0.6099293133369962 and parameters: {'hidden_dim': 111, 'id_embed_dim': 16, 'lr': 0.009324385177711444, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:50,360] Trial 131 finished with value: 0.5346416763793257 and parameters: {'hidden_dim': 97, 'id_embed_dim': 16, 'lr': 0.0047376583219997355, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:50,535] Trial 132 finished with value: 0.623551032596961 and parameters: {'hidden_dim': 96, 'id_embed_dim': 16, 'lr': 0.00483234994956244, 'batch_size': 64}. Best is trial 73 with value: 0.5059609511741122.\n",
      "[I 2025-04-19 16:26:50,706] Trial 133 finished with value: 0.49886903547702877 and parameters: {'hidden_dim': 94, 'id_embed_dim': 16, 'lr': 0.0058133607138416005, 'batch_size': 64}. Best is trial 133 with value: 0.49886903547702877.\n",
      "[I 2025-04-19 16:26:50,881] Trial 134 finished with value: 0.6143690016036644 and parameters: {'hidden_dim': 94, 'id_embed_dim': 16, 'lr': 0.0059553885477276036, 'batch_size': 64}. Best is trial 133 with value: 0.49886903547702877.\n",
      "[I 2025-04-19 16:26:51,063] Trial 135 finished with value: 0.5623709196434882 and parameters: {'hidden_dim': 91, 'id_embed_dim': 16, 'lr': 0.003439036469266858, 'batch_size': 64}. Best is trial 133 with value: 0.49886903547702877.\n",
      "[I 2025-04-19 16:26:51,238] Trial 136 finished with value: 0.5206135565176943 and parameters: {'hidden_dim': 98, 'id_embed_dim': 15, 'lr': 0.004428313841191081, 'batch_size': 64}. Best is trial 133 with value: 0.49886903547702877.\n",
      "[I 2025-04-19 16:26:51,430] Trial 137 finished with value: 0.6992143311894926 and parameters: {'hidden_dim': 98, 'id_embed_dim': 15, 'lr': 0.004299899797860439, 'batch_size': 64}. Best is trial 133 with value: 0.49886903547702877.\n",
      "[I 2025-04-19 16:26:51,617] Trial 138 finished with value: 0.6327967240398091 and parameters: {'hidden_dim': 101, 'id_embed_dim': 15, 'lr': 0.004937734461709424, 'batch_size': 64}. Best is trial 133 with value: 0.49886903547702877.\n",
      "[I 2025-04-19 16:26:51,816] Trial 139 finished with value: 0.5303265488237366 and parameters: {'hidden_dim': 99, 'id_embed_dim': 16, 'lr': 0.007446588493257059, 'batch_size': 64}. Best is trial 133 with value: 0.49886903547702877.\n",
      "[I 2025-04-19 16:26:51,996] Trial 140 finished with value: 0.47582017389455233 and parameters: {'hidden_dim': 97, 'id_embed_dim': 16, 'lr': 0.007646964495351773, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:52,169] Trial 141 finished with value: 0.646434834128932 and parameters: {'hidden_dim': 97, 'id_embed_dim': 16, 'lr': 0.007591835243576322, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:52,348] Trial 142 finished with value: 0.5068476567591044 and parameters: {'hidden_dim': 99, 'id_embed_dim': 16, 'lr': 0.0071581727837700115, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:52,530] Trial 143 finished with value: 0.5610559685785967 and parameters: {'hidden_dim': 99, 'id_embed_dim': 16, 'lr': 0.006991885882015569, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:52,717] Trial 144 finished with value: 0.5302461143723107 and parameters: {'hidden_dim': 95, 'id_embed_dim': 16, 'lr': 0.006240887586689601, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:52,897] Trial 145 finished with value: 0.546014113981921 and parameters: {'hidden_dim': 95, 'id_embed_dim': 16, 'lr': 0.008505830940645515, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:53,075] Trial 146 finished with value: 0.5808312140013042 and parameters: {'hidden_dim': 93, 'id_embed_dim': 16, 'lr': 0.006470270281845851, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:53,246] Trial 147 finished with value: 0.5017865277770767 and parameters: {'hidden_dim': 90, 'id_embed_dim': 16, 'lr': 0.007543721213136238, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:53,439] Trial 148 finished with value: 0.4954812118881627 and parameters: {'hidden_dim': 91, 'id_embed_dim': 16, 'lr': 0.009850393916207078, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:53,628] Trial 149 finished with value: 0.7254244375945931 and parameters: {'hidden_dim': 89, 'id_embed_dim': 15, 'lr': 0.009511156283164431, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:53,819] Trial 150 finished with value: 0.5182491021048754 and parameters: {'hidden_dim': 91, 'id_embed_dim': 16, 'lr': 0.007385670758710182, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:54,061] Trial 151 finished with value: 0.7165816359053877 and parameters: {'hidden_dim': 91, 'id_embed_dim': 16, 'lr': 0.009885907100849476, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:54,249] Trial 152 finished with value: 0.4786057678380407 and parameters: {'hidden_dim': 88, 'id_embed_dim': 16, 'lr': 0.0077116651750186276, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:54,427] Trial 153 finished with value: 0.5881055745863377 and parameters: {'hidden_dim': 90, 'id_embed_dim': 16, 'lr': 0.008046081781527605, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:54,604] Trial 154 finished with value: 0.6005851711545672 and parameters: {'hidden_dim': 87, 'id_embed_dim': 16, 'lr': 0.007284422491629348, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:54,786] Trial 155 finished with value: 0.6525314163444633 and parameters: {'hidden_dim': 92, 'id_embed_dim': 16, 'lr': 0.009087490232642718, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:54,966] Trial 156 finished with value: 0.4769261501785508 and parameters: {'hidden_dim': 95, 'id_embed_dim': 16, 'lr': 0.008483268989685598, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:55,147] Trial 157 finished with value: 0.6705476018719208 and parameters: {'hidden_dim': 95, 'id_embed_dim': 16, 'lr': 0.008281250104392741, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:55,286] Trial 158 finished with value: 0.7225166474069867 and parameters: {'hidden_dim': 86, 'id_embed_dim': 16, 'lr': 0.007611768849115082, 'batch_size': 128}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:55,471] Trial 159 finished with value: 0.5045606355021771 and parameters: {'hidden_dim': 94, 'id_embed_dim': 15, 'lr': 0.006817050366923276, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:55,660] Trial 160 finished with value: 0.7385306264224806 and parameters: {'hidden_dim': 89, 'id_embed_dim': 15, 'lr': 0.008896461949186835, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:55,850] Trial 161 finished with value: 0.5504463767646847 and parameters: {'hidden_dim': 95, 'id_embed_dim': 16, 'lr': 0.006789977291247395, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:56,025] Trial 162 finished with value: 0.5414608035768781 and parameters: {'hidden_dim': 94, 'id_embed_dim': 15, 'lr': 0.007506453502210623, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:56,214] Trial 163 finished with value: 0.5439042726853737 and parameters: {'hidden_dim': 92, 'id_embed_dim': 16, 'lr': 0.008252353878248693, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:56,400] Trial 164 finished with value: 0.6475961871613237 and parameters: {'hidden_dim': 99, 'id_embed_dim': 16, 'lr': 0.006729434987121455, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:56,577] Trial 165 finished with value: 0.49914138747337167 and parameters: {'hidden_dim': 88, 'id_embed_dim': 15, 'lr': 0.006205959018994286, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:56,745] Trial 166 finished with value: 0.5393714815154111 and parameters: {'hidden_dim': 82, 'id_embed_dim': 15, 'lr': 0.006310535277362036, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:56,917] Trial 167 finished with value: 0.5635764504733839 and parameters: {'hidden_dim': 88, 'id_embed_dim': 15, 'lr': 0.008831215782835957, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:57,086] Trial 168 finished with value: 0.5066374015987367 and parameters: {'hidden_dim': 84, 'id_embed_dim': 15, 'lr': 0.006103244173011981, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:57,258] Trial 169 finished with value: 0.5361629348052176 and parameters: {'hidden_dim': 78, 'id_embed_dim': 14, 'lr': 0.007910214024691166, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:57,424] Trial 170 finished with value: 0.7008181604227626 and parameters: {'hidden_dim': 84, 'id_embed_dim': 15, 'lr': 0.006718261672673238, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:57,592] Trial 171 finished with value: 0.5552815163045898 and parameters: {'hidden_dim': 90, 'id_embed_dim': 15, 'lr': 0.006015851200848149, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:57,764] Trial 172 finished with value: 0.6834774465489208 and parameters: {'hidden_dim': 85, 'id_embed_dim': 15, 'lr': 0.00624913536012427, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:57,949] Trial 173 finished with value: 0.5257393565393031 and parameters: {'hidden_dim': 91, 'id_embed_dim': 15, 'lr': 0.007220425305559721, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:58,113] Trial 174 finished with value: 0.6072437592915126 and parameters: {'hidden_dim': 88, 'id_embed_dim': 14, 'lr': 0.007439373098107529, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:58,281] Trial 175 finished with value: 0.5238060122145746 and parameters: {'hidden_dim': 91, 'id_embed_dim': 15, 'lr': 0.009924538000526171, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:58,468] Trial 176 finished with value: 0.624301851243901 and parameters: {'hidden_dim': 91, 'id_embed_dim': 15, 'lr': 0.00989142790707283, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:58,647] Trial 177 finished with value: 0.6289506070595935 and parameters: {'hidden_dim': 93, 'id_embed_dim': 14, 'lr': 0.008826907154623953, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:58,842] Trial 178 finished with value: 0.5405394663488058 and parameters: {'hidden_dim': 86, 'id_embed_dim': 15, 'lr': 0.007107159621129533, 'batch_size': 64}. Best is trial 140 with value: 0.47582017389455233.\n",
      "[I 2025-04-19 16:26:59,023] Trial 179 finished with value: 0.4736570962389609 and parameters: {'hidden_dim': 90, 'id_embed_dim': 15, 'lr': 0.008043821952250464, 'batch_size': 64}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:26:59,204] Trial 180 finished with value: 0.789094592843737 and parameters: {'hidden_dim': 88, 'id_embed_dim': 15, 'lr': 0.008064698914383907, 'batch_size': 64}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:26:59,378] Trial 181 finished with value: 0.5555218386470824 and parameters: {'hidden_dim': 90, 'id_embed_dim': 15, 'lr': 0.009925803053195618, 'batch_size': 64}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:26:59,556] Trial 182 finished with value: 0.6294060954473969 and parameters: {'hidden_dim': 93, 'id_embed_dim': 15, 'lr': 0.008651952192849558, 'batch_size': 64}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:26:59,730] Trial 183 finished with value: 0.6015003202553082 and parameters: {'hidden_dim': 84, 'id_embed_dim': 16, 'lr': 0.005576928874022029, 'batch_size': 64}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:26:59,909] Trial 184 finished with value: 0.5488488503864833 and parameters: {'hidden_dim': 91, 'id_embed_dim': 15, 'lr': 0.006831218790219098, 'batch_size': 64}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:00,082] Trial 185 finished with value: 0.6698157231610521 and parameters: {'hidden_dim': 89, 'id_embed_dim': 16, 'lr': 0.00795236116995468, 'batch_size': 64}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:00,222] Trial 186 finished with value: 0.5149934327692017 and parameters: {'hidden_dim': 97, 'id_embed_dim': 15, 'lr': 0.009125387221054323, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:00,368] Trial 187 finished with value: 0.5055076206537118 and parameters: {'hidden_dim': 97, 'id_embed_dim': 14, 'lr': 0.00877092336476242, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:00,509] Trial 188 finished with value: 0.5171829784723153 and parameters: {'hidden_dim': 97, 'id_embed_dim': 14, 'lr': 0.009602277767100388, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:00,649] Trial 189 finished with value: 0.5355041322851539 and parameters: {'hidden_dim': 97, 'id_embed_dim': 14, 'lr': 0.00894950313622558, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:00,789] Trial 190 finished with value: 0.5698932606474798 and parameters: {'hidden_dim': 97, 'id_embed_dim': 14, 'lr': 0.008423242227596047, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:00,930] Trial 191 finished with value: 0.5437237239421758 and parameters: {'hidden_dim': 95, 'id_embed_dim': 16, 'lr': 0.009945622130841242, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:01,072] Trial 192 finished with value: 0.5216208978703147 and parameters: {'hidden_dim': 96, 'id_embed_dim': 16, 'lr': 0.009266367624590419, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:01,214] Trial 193 finished with value: 0.5423203209289035 and parameters: {'hidden_dim': 100, 'id_embed_dim': 16, 'lr': 0.008926407845457333, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:01,350] Trial 194 finished with value: 0.6804000874211017 and parameters: {'hidden_dim': 97, 'id_embed_dim': 16, 'lr': 0.007746918096762374, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:01,493] Trial 195 finished with value: 0.5326732128186333 and parameters: {'hidden_dim': 94, 'id_embed_dim': 16, 'lr': 0.00918553865518685, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:01,630] Trial 196 finished with value: 45.9335476294496 and parameters: {'hidden_dim': 98, 'id_embed_dim': 16, 'lr': 0.0001027139410376022, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:01,773] Trial 197 finished with value: 0.519892310289512 and parameters: {'hidden_dim': 100, 'id_embed_dim': 16, 'lr': 0.007903661893387336, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:01,915] Trial 198 finished with value: 0.7271014021751576 and parameters: {'hidden_dim': 101, 'id_embed_dim': 16, 'lr': 0.007254022864617558, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n",
      "[I 2025-04-19 16:27:02,057] Trial 199 finished with value: 0.5200510401474802 and parameters: {'hidden_dim': 99, 'id_embed_dim': 16, 'lr': 0.008039534155363903, 'batch_size': 128}. Best is trial 179 with value: 0.4736570962389609.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparams: {'hidden_dim': 90, 'id_embed_dim': 15, 'lr': 0.008043821952250464, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(lambda trial: objective(trial, train_df_split, val_df_split, id_map, input_dim, id_count, device), n_trials=200)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparams:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "882142fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "model = RNNRegressor(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    id_count=id_count,\n",
    "    id_embed_dim=best_params['id_embed_dim'],\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=best_params['lr'])\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_loader = DataLoader(MoodDataset(train_df_split, id_map), batch_size=best_params['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(MoodDataset(val_df_split, id_map), batch_size=best_params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cc6f057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 35.3945, val loss = 11.4038\n",
      "Epoch 2: train loss = 4.9494, val loss = 1.7650\n",
      "Epoch 3: train loss = 1.0849, val loss = 0.6984\n",
      "Epoch 4: train loss = 0.4755, val loss = 0.5735\n",
      "Epoch 5: train loss = 0.3836, val loss = 0.5234\n",
      "Epoch 6: train loss = 0.3586, val loss = 0.5383\n",
      "Epoch 7: train loss = 0.3480, val loss = 0.5010\n",
      "Epoch 8: train loss = 0.3271, val loss = 0.5147\n",
      "Epoch 9: train loss = 0.3206, val loss = 0.4980\n",
      "Epoch 10: train loss = 0.3141, val loss = 0.5076\n",
      "Epoch 11: train loss = 0.2966, val loss = 0.4980\n",
      "Epoch 12: train loss = 0.2914, val loss = 0.5229\n",
      "Epoch 13: train loss = 0.2761, val loss = 0.4877\n",
      "Epoch 14: train loss = 0.2748, val loss = 0.5709\n",
      "Epoch 15: train loss = 0.2619, val loss = 0.5230\n",
      "Epoch 16: train loss = 0.2505, val loss = 0.5613\n",
      "Epoch 17: train loss = 0.2404, val loss = 0.5656\n",
      "Epoch 18: train loss = 0.2284, val loss = 0.6183\n",
      "Epoch 19: train loss = 0.2163, val loss = 0.5933\n",
      "Epoch 20: train loss = 0.2110, val loss = 0.6268\n",
      "Epoch 21: train loss = 0.2052, val loss = 0.6561\n",
      "Epoch 22: train loss = 0.1966, val loss = 0.6490\n",
      "Epoch 23: train loss = 0.1923, val loss = 0.7146\n",
      "Epoch 24: train loss = 0.1800, val loss = 0.7011\n",
      "Epoch 25: train loss = 0.1722, val loss = 0.7372\n",
      "Epoch 26: train loss = 0.1638, val loss = 0.7365\n",
      "Epoch 27: train loss = 0.1614, val loss = 0.7572\n",
      "Epoch 28: train loss = 0.1492, val loss = 0.7691\n",
      "Epoch 29: train loss = 0.1506, val loss = 0.7947\n",
      "Epoch 30: train loss = 0.1394, val loss = 0.7728\n",
      "Epoch 31: train loss = 0.1317, val loss = 0.8611\n",
      "Epoch 32: train loss = 0.1241, val loss = 0.8055\n",
      "Epoch 33: train loss = 0.1274, val loss = 0.8580\n",
      "Epoch 34: train loss = 0.1134, val loss = 0.8185\n",
      "Epoch 35: train loss = 0.1058, val loss = 0.8166\n",
      "Epoch 36: train loss = 0.1020, val loss = 0.8561\n",
      "Epoch 37: train loss = 0.0942, val loss = 0.8679\n",
      "Epoch 38: train loss = 0.0898, val loss = 0.8906\n",
      "Epoch 39: train loss = 0.0876, val loss = 0.8965\n",
      "Epoch 40: train loss = 0.0848, val loss = 0.8908\n",
      "Epoch 41: train loss = 0.0780, val loss = 0.9563\n",
      "Epoch 42: train loss = 0.0756, val loss = 0.8973\n",
      "Epoch 43: train loss = 0.0699, val loss = 0.9455\n",
      "Epoch 44: train loss = 0.0670, val loss = 0.9256\n",
      "Epoch 45: train loss = 0.0682, val loss = 0.9986\n",
      "Epoch 46: train loss = 0.0572, val loss = 0.9472\n",
      "Epoch 47: train loss = 0.0561, val loss = 0.9417\n",
      "Epoch 48: train loss = 0.0496, val loss = 0.9322\n",
      "Epoch 49: train loss = 0.0465, val loss = 0.9605\n",
      "Epoch 50: train loss = 0.0455, val loss = 0.9522\n",
      "Epoch 51: train loss = 0.0435, val loss = 0.9308\n",
      "Epoch 52: train loss = 0.0408, val loss = 1.0112\n",
      "Epoch 53: train loss = 0.0383, val loss = 0.9383\n",
      "Epoch 54: train loss = 0.0361, val loss = 0.9677\n",
      "Epoch 55: train loss = 0.0343, val loss = 0.9487\n",
      "Epoch 56: train loss = 0.0313, val loss = 0.9572\n",
      "Epoch 57: train loss = 0.0283, val loss = 0.9680\n",
      "Epoch 58: train loss = 0.0289, val loss = 0.9924\n",
      "Epoch 59: train loss = 0.0254, val loss = 0.9832\n",
      "Epoch 60: train loss = 0.0236, val loss = 0.9983\n",
      "Epoch 61: train loss = 0.0241, val loss = 1.0047\n",
      "Epoch 62: train loss = 0.0198, val loss = 1.0053\n",
      "Epoch 63: train loss = 0.0200, val loss = 1.0051\n",
      "Epoch 64: train loss = 0.0178, val loss = 1.0150\n",
      "Epoch 65: train loss = 0.0161, val loss = 1.0156\n",
      "Epoch 66: train loss = 0.0162, val loss = 1.0315\n",
      "Epoch 67: train loss = 0.0151, val loss = 1.0248\n",
      "Epoch 68: train loss = 0.0141, val loss = 0.9776\n",
      "Epoch 69: train loss = 0.0127, val loss = 1.0211\n",
      "Epoch 70: train loss = 0.0118, val loss = 1.0045\n",
      "Epoch 71: train loss = 0.0115, val loss = 1.0174\n",
      "Epoch 72: train loss = 0.0113, val loss = 1.0144\n",
      "Epoch 73: train loss = 0.0104, val loss = 0.9985\n",
      "Epoch 74: train loss = 0.0099, val loss = 0.9997\n",
      "Epoch 75: train loss = 0.0092, val loss = 1.0497\n",
      "Epoch 76: train loss = 0.0083, val loss = 1.0282\n",
      "Epoch 77: train loss = 0.0078, val loss = 1.0423\n",
      "Epoch 78: train loss = 0.0079, val loss = 1.0095\n",
      "Epoch 79: train loss = 0.0075, val loss = 1.0296\n",
      "Epoch 80: train loss = 0.0080, val loss = 1.0416\n",
      "Epoch 81: train loss = 0.0074, val loss = 1.0472\n",
      "Epoch 82: train loss = 0.0068, val loss = 1.0570\n",
      "Epoch 83: train loss = 0.0061, val loss = 1.0356\n",
      "Epoch 84: train loss = 0.0057, val loss = 1.0635\n",
      "Epoch 85: train loss = 0.0064, val loss = 1.0570\n",
      "Epoch 86: train loss = 0.0068, val loss = 1.0549\n",
      "Epoch 87: train loss = 0.0068, val loss = 1.0316\n",
      "Epoch 88: train loss = 0.0061, val loss = 1.0967\n",
      "Epoch 89: train loss = 0.0056, val loss = 1.0315\n",
      "Epoch 90: train loss = 0.0051, val loss = 1.0871\n",
      "Epoch 91: train loss = 0.0051, val loss = 1.0366\n",
      "Epoch 92: train loss = 0.0059, val loss = 1.0357\n",
      "Epoch 93: train loss = 0.0050, val loss = 1.0974\n",
      "Epoch 94: train loss = 0.0049, val loss = 1.0448\n",
      "Epoch 95: train loss = 0.0049, val loss = 1.0568\n",
      "Epoch 96: train loss = 0.0041, val loss = 1.0469\n",
      "Epoch 97: train loss = 0.0042, val loss = 1.0655\n",
      "Epoch 98: train loss = 0.0048, val loss = 1.0725\n",
      "Epoch 99: train loss = 0.0045, val loss = 1.0371\n",
      "Epoch 100: train loss = 0.0050, val loss = 1.0718\n",
      "Epoch 101: train loss = 0.0043, val loss = 1.0316\n",
      "Epoch 102: train loss = 0.0048, val loss = 1.0417\n",
      "Epoch 103: train loss = 0.0043, val loss = 1.0670\n",
      "Epoch 104: train loss = 0.0050, val loss = 1.0853\n",
      "Epoch 105: train loss = 0.0048, val loss = 1.0589\n",
      "Epoch 106: train loss = 0.0042, val loss = 1.0839\n",
      "Epoch 107: train loss = 0.0038, val loss = 1.0503\n",
      "Epoch 108: train loss = 0.0035, val loss = 1.0871\n",
      "Epoch 109: train loss = 0.0038, val loss = 1.0690\n",
      "Epoch 110: train loss = 0.0041, val loss = 1.0841\n",
      "Epoch 111: train loss = 0.0038, val loss = 1.0739\n",
      "Epoch 112: train loss = 0.0033, val loss = 1.1065\n",
      "Epoch 113: train loss = 0.0036, val loss = 1.0556\n",
      "Epoch 114: train loss = 0.0035, val loss = 1.0760\n",
      "Epoch 115: train loss = 0.0031, val loss = 1.0612\n",
      "Epoch 116: train loss = 0.0035, val loss = 1.0757\n",
      "Epoch 117: train loss = 0.0042, val loss = 1.0867\n",
      "Epoch 118: train loss = 0.0042, val loss = 1.0655\n",
      "Epoch 119: train loss = 0.0036, val loss = 1.0917\n",
      "Epoch 120: train loss = 0.0035, val loss = 1.0885\n",
      "Epoch 121: train loss = 0.0039, val loss = 1.0755\n",
      "Epoch 122: train loss = 0.0037, val loss = 1.0734\n",
      "Epoch 123: train loss = 0.0035, val loss = 1.0818\n",
      "Epoch 124: train loss = 0.0043, val loss = 1.0892\n",
      "Epoch 125: train loss = 0.0034, val loss = 1.1152\n",
      "Epoch 126: train loss = 0.0040, val loss = 1.0891\n",
      "Epoch 127: train loss = 0.0036, val loss = 1.1082\n",
      "Epoch 128: train loss = 0.0038, val loss = 1.0577\n",
      "Epoch 129: train loss = 0.0038, val loss = 1.0825\n",
      "Epoch 130: train loss = 0.0038, val loss = 1.0877\n",
      "Epoch 131: train loss = 0.0037, val loss = 1.0864\n",
      "Epoch 132: train loss = 0.0043, val loss = 1.0995\n",
      "Epoch 133: train loss = 0.0041, val loss = 1.0704\n",
      "Epoch 134: train loss = 0.0044, val loss = 1.1102\n",
      "Epoch 135: train loss = 0.0048, val loss = 1.0747\n",
      "Epoch 136: train loss = 0.0067, val loss = 1.1124\n",
      "Epoch 137: train loss = 0.0072, val loss = 1.1154\n",
      "Epoch 138: train loss = 0.0069, val loss = 1.0638\n",
      "Epoch 139: train loss = 0.0077, val loss = 1.0342\n",
      "Epoch 140: train loss = 0.0080, val loss = 1.0739\n",
      "Epoch 141: train loss = 0.0099, val loss = 1.1034\n",
      "Epoch 142: train loss = 0.0103, val loss = 1.0619\n",
      "Epoch 143: train loss = 0.0086, val loss = 1.0614\n",
      "Epoch 144: train loss = 0.0100, val loss = 1.1308\n",
      "Epoch 145: train loss = 0.0088, val loss = 1.0847\n",
      "Epoch 146: train loss = 0.0079, val loss = 1.0592\n",
      "Epoch 147: train loss = 0.0069, val loss = 1.0996\n",
      "Epoch 148: train loss = 0.0061, val loss = 1.0715\n",
      "Epoch 149: train loss = 0.0056, val loss = 1.0888\n",
      "Epoch 150: train loss = 0.0054, val loss = 1.0803\n",
      "Epoch 151: train loss = 0.0053, val loss = 1.0529\n",
      "Epoch 152: train loss = 0.0066, val loss = 1.0648\n",
      "Epoch 153: train loss = 0.0053, val loss = 1.0534\n",
      "Epoch 154: train loss = 0.0049, val loss = 1.1073\n",
      "Epoch 155: train loss = 0.0050, val loss = 1.0712\n",
      "Epoch 156: train loss = 0.0055, val loss = 1.0641\n",
      "Epoch 157: train loss = 0.0056, val loss = 1.0825\n",
      "Epoch 158: train loss = 0.0053, val loss = 1.0275\n",
      "Epoch 159: train loss = 0.0039, val loss = 1.0405\n",
      "Epoch 160: train loss = 0.0044, val loss = 1.0277\n",
      "Epoch 161: train loss = 0.0038, val loss = 1.0784\n",
      "Epoch 162: train loss = 0.0046, val loss = 1.0399\n",
      "Epoch 163: train loss = 0.0058, val loss = 1.0497\n",
      "Epoch 164: train loss = 0.0060, val loss = 1.0384\n",
      "Epoch 165: train loss = 0.0071, val loss = 1.0277\n",
      "Epoch 166: train loss = 0.0055, val loss = 1.0411\n",
      "Epoch 167: train loss = 0.0057, val loss = 1.0505\n",
      "Epoch 168: train loss = 0.0055, val loss = 1.0180\n",
      "Epoch 169: train loss = 0.0057, val loss = 1.0211\n",
      "Epoch 170: train loss = 0.0061, val loss = 1.0583\n",
      "Epoch 171: train loss = 0.0069, val loss = 1.0405\n",
      "Epoch 172: train loss = 0.0109, val loss = 1.0809\n",
      "Epoch 173: train loss = 0.0107, val loss = 1.0159\n",
      "Epoch 174: train loss = 0.0155, val loss = 1.1035\n",
      "Epoch 175: train loss = 0.0189, val loss = 1.0398\n",
      "Epoch 176: train loss = 0.0170, val loss = 1.0246\n",
      "Epoch 177: train loss = 0.0170, val loss = 0.9493\n",
      "Epoch 178: train loss = 0.0204, val loss = 1.0219\n",
      "Epoch 179: train loss = 0.0150, val loss = 0.9790\n",
      "Epoch 180: train loss = 0.0111, val loss = 0.9839\n",
      "Epoch 181: train loss = 0.0120, val loss = 1.0109\n",
      "Epoch 182: train loss = 0.0122, val loss = 0.9714\n",
      "Epoch 183: train loss = 0.0136, val loss = 0.9271\n",
      "Epoch 184: train loss = 0.0142, val loss = 1.0005\n",
      "Epoch 185: train loss = 0.0138, val loss = 0.9474\n",
      "Epoch 186: train loss = 0.0128, val loss = 0.9782\n",
      "Epoch 187: train loss = 0.0103, val loss = 0.9271\n",
      "Epoch 188: train loss = 0.0092, val loss = 0.9545\n",
      "Epoch 189: train loss = 0.0073, val loss = 0.9512\n",
      "Epoch 190: train loss = 0.0074, val loss = 1.0233\n",
      "Epoch 191: train loss = 0.0098, val loss = 0.9459\n",
      "Epoch 192: train loss = 0.0088, val loss = 0.9764\n",
      "Epoch 193: train loss = 0.0071, val loss = 0.9623\n",
      "Epoch 194: train loss = 0.0069, val loss = 1.0212\n",
      "Epoch 195: train loss = 0.0065, val loss = 0.9604\n",
      "Epoch 196: train loss = 0.0064, val loss = 0.9959\n",
      "Epoch 197: train loss = 0.0051, val loss = 0.9818\n",
      "Epoch 198: train loss = 0.0048, val loss = 0.9543\n",
      "Epoch 199: train loss = 0.0051, val loss = 1.0032\n",
      "Epoch 200: train loss = 0.0046, val loss = 0.9647\n",
      "Epoch 201: train loss = 0.0040, val loss = 0.9728\n",
      "Epoch 202: train loss = 0.0031, val loss = 0.9309\n",
      "Epoch 203: train loss = 0.0029, val loss = 0.9488\n",
      "Epoch 204: train loss = 0.0023, val loss = 0.9711\n",
      "Epoch 205: train loss = 0.0026, val loss = 0.9521\n",
      "Epoch 206: train loss = 0.0022, val loss = 0.9688\n",
      "Epoch 207: train loss = 0.0023, val loss = 0.9528\n",
      "Epoch 208: train loss = 0.0017, val loss = 0.9645\n",
      "Epoch 209: train loss = 0.0015, val loss = 0.9893\n",
      "Epoch 210: train loss = 0.0017, val loss = 0.9452\n",
      "Epoch 211: train loss = 0.0018, val loss = 0.9591\n",
      "Epoch 212: train loss = 0.0017, val loss = 0.9786\n",
      "Epoch 213: train loss = 0.0016, val loss = 0.9778\n",
      "Epoch 214: train loss = 0.0017, val loss = 0.9523\n",
      "Epoch 215: train loss = 0.0016, val loss = 0.9715\n",
      "Epoch 216: train loss = 0.0017, val loss = 0.9719\n",
      "Epoch 217: train loss = 0.0017, val loss = 0.9708\n",
      "Epoch 218: train loss = 0.0018, val loss = 0.9743\n",
      "Epoch 219: train loss = 0.0015, val loss = 0.9547\n",
      "Epoch 220: train loss = 0.0014, val loss = 0.9661\n",
      "Epoch 221: train loss = 0.0013, val loss = 0.9721\n",
      "Epoch 222: train loss = 0.0013, val loss = 0.9724\n",
      "Epoch 223: train loss = 0.0012, val loss = 0.9551\n",
      "Epoch 224: train loss = 0.0014, val loss = 0.9767\n",
      "Epoch 225: train loss = 0.0013, val loss = 0.9488\n",
      "Epoch 226: train loss = 0.0013, val loss = 0.9509\n",
      "Epoch 227: train loss = 0.0013, val loss = 0.9629\n",
      "Epoch 228: train loss = 0.0018, val loss = 1.0061\n",
      "Epoch 229: train loss = 0.0021, val loss = 0.9680\n",
      "Epoch 230: train loss = 0.0032, val loss = 0.9645\n",
      "Epoch 231: train loss = 0.0022, val loss = 0.9627\n",
      "Epoch 232: train loss = 0.0023, val loss = 0.9676\n",
      "Epoch 233: train loss = 0.0023, val loss = 0.9449\n",
      "Epoch 234: train loss = 0.0022, val loss = 0.9735\n",
      "Epoch 235: train loss = 0.0027, val loss = 0.9827\n",
      "Epoch 236: train loss = 0.0031, val loss = 0.9297\n",
      "Epoch 237: train loss = 0.0033, val loss = 0.9516\n",
      "Epoch 238: train loss = 0.0047, val loss = 0.9654\n",
      "Epoch 239: train loss = 0.0051, val loss = 0.9832\n",
      "Epoch 240: train loss = 0.0066, val loss = 1.0036\n",
      "Epoch 241: train loss = 0.0113, val loss = 0.9615\n",
      "Epoch 242: train loss = 0.0133, val loss = 0.9273\n",
      "Epoch 243: train loss = 0.0171, val loss = 1.0102\n",
      "Epoch 244: train loss = 0.0162, val loss = 0.9937\n",
      "Epoch 245: train loss = 0.0181, val loss = 0.9031\n",
      "Epoch 246: train loss = 0.0193, val loss = 0.8892\n",
      "Epoch 247: train loss = 0.0181, val loss = 0.9676\n",
      "Epoch 248: train loss = 0.0160, val loss = 0.9157\n",
      "Epoch 249: train loss = 0.0137, val loss = 0.9500\n",
      "Epoch 250: train loss = 0.0120, val loss = 0.9465\n",
      "Epoch 251: train loss = 0.0105, val loss = 0.9027\n",
      "Epoch 252: train loss = 0.0085, val loss = 0.9218\n",
      "Epoch 253: train loss = 0.0067, val loss = 0.9059\n",
      "Epoch 254: train loss = 0.0061, val loss = 0.9354\n",
      "Epoch 255: train loss = 0.0046, val loss = 0.8910\n",
      "Epoch 256: train loss = 0.0043, val loss = 0.9140\n",
      "Epoch 257: train loss = 0.0041, val loss = 0.9206\n",
      "Epoch 258: train loss = 0.0031, val loss = 0.9299\n",
      "Epoch 259: train loss = 0.0032, val loss = 0.9206\n",
      "Epoch 260: train loss = 0.0037, val loss = 0.9123\n",
      "Epoch 261: train loss = 0.0041, val loss = 0.9316\n",
      "Epoch 262: train loss = 0.0039, val loss = 0.9000\n",
      "Epoch 263: train loss = 0.0045, val loss = 0.9246\n",
      "Epoch 264: train loss = 0.0039, val loss = 0.9428\n",
      "Epoch 265: train loss = 0.0039, val loss = 0.9242\n",
      "Epoch 266: train loss = 0.0058, val loss = 0.8977\n",
      "Epoch 267: train loss = 0.0045, val loss = 0.8966\n",
      "Epoch 268: train loss = 0.0049, val loss = 0.9453\n",
      "Epoch 269: train loss = 0.0040, val loss = 0.9210\n",
      "Epoch 270: train loss = 0.0040, val loss = 0.9271\n",
      "Epoch 271: train loss = 0.0038, val loss = 0.9212\n",
      "Epoch 272: train loss = 0.0034, val loss = 0.9190\n",
      "Epoch 273: train loss = 0.0034, val loss = 0.9112\n",
      "Epoch 274: train loss = 0.0040, val loss = 0.9671\n",
      "Epoch 275: train loss = 0.0039, val loss = 0.8959\n",
      "Epoch 276: train loss = 0.0036, val loss = 0.9262\n",
      "Epoch 277: train loss = 0.0032, val loss = 0.9136\n",
      "Epoch 278: train loss = 0.0029, val loss = 0.9165\n",
      "Epoch 279: train loss = 0.0034, val loss = 0.9005\n",
      "Epoch 280: train loss = 0.0044, val loss = 0.9142\n",
      "Epoch 281: train loss = 0.0040, val loss = 0.9176\n",
      "Epoch 282: train loss = 0.0034, val loss = 0.9295\n",
      "Epoch 283: train loss = 0.0035, val loss = 0.9304\n",
      "Epoch 284: train loss = 0.0032, val loss = 0.9039\n",
      "Epoch 285: train loss = 0.0035, val loss = 0.9308\n",
      "Epoch 286: train loss = 0.0039, val loss = 0.9136\n",
      "Epoch 287: train loss = 0.0049, val loss = 0.9095\n",
      "Epoch 288: train loss = 0.0050, val loss = 0.8917\n",
      "Epoch 289: train loss = 0.0053, val loss = 0.9229\n",
      "Epoch 290: train loss = 0.0055, val loss = 0.8750\n",
      "Epoch 291: train loss = 0.0055, val loss = 0.9201\n",
      "Epoch 292: train loss = 0.0053, val loss = 0.8561\n",
      "Epoch 293: train loss = 0.0043, val loss = 0.9138\n",
      "Epoch 294: train loss = 0.0044, val loss = 0.8902\n",
      "Epoch 295: train loss = 0.0065, val loss = 0.9028\n",
      "Epoch 296: train loss = 0.0067, val loss = 0.9214\n",
      "Epoch 297: train loss = 0.0064, val loss = 0.8733\n",
      "Epoch 298: train loss = 0.0043, val loss = 0.9160\n",
      "Epoch 299: train loss = 0.0045, val loss = 0.8814\n",
      "Epoch 300: train loss = 0.0072, val loss = 0.8618\n",
      "Epoch 301: train loss = 0.0086, val loss = 0.8780\n",
      "Epoch 302: train loss = 0.0093, val loss = 0.9298\n",
      "Epoch 303: train loss = 0.0093, val loss = 0.8653\n",
      "Epoch 304: train loss = 0.0087, val loss = 0.8850\n",
      "Epoch 305: train loss = 0.0092, val loss = 0.9152\n",
      "Epoch 306: train loss = 0.0106, val loss = 0.8232\n",
      "Epoch 307: train loss = 0.0106, val loss = 0.9471\n",
      "Epoch 308: train loss = 0.0093, val loss = 0.8674\n",
      "Epoch 309: train loss = 0.0097, val loss = 0.9199\n",
      "Epoch 310: train loss = 0.0110, val loss = 0.9114\n",
      "Epoch 311: train loss = 0.0109, val loss = 0.8586\n",
      "Epoch 312: train loss = 0.0106, val loss = 0.9096\n",
      "Epoch 313: train loss = 0.0105, val loss = 0.9010\n",
      "Epoch 314: train loss = 0.0086, val loss = 0.8727\n",
      "Epoch 315: train loss = 0.0141, val loss = 0.8395\n",
      "Epoch 316: train loss = 0.0137, val loss = 0.9040\n",
      "Epoch 317: train loss = 0.0144, val loss = 0.8372\n",
      "Epoch 318: train loss = 0.0209, val loss = 0.8764\n",
      "Epoch 319: train loss = 0.0145, val loss = 0.8747\n",
      "Epoch 320: train loss = 0.0088, val loss = 0.9134\n",
      "Epoch 321: train loss = 0.0109, val loss = 0.8947\n",
      "Epoch 322: train loss = 0.0079, val loss = 0.8988\n",
      "Epoch 323: train loss = 0.0063, val loss = 0.8571\n",
      "Epoch 324: train loss = 0.0049, val loss = 0.8568\n",
      "Epoch 325: train loss = 0.0040, val loss = 0.8750\n",
      "Epoch 326: train loss = 0.0035, val loss = 0.8782\n",
      "Epoch 327: train loss = 0.0032, val loss = 0.8714\n",
      "Epoch 328: train loss = 0.0023, val loss = 0.8725\n",
      "Epoch 329: train loss = 0.0026, val loss = 0.8644\n",
      "Epoch 330: train loss = 0.0023, val loss = 0.8640\n",
      "Epoch 331: train loss = 0.0018, val loss = 0.8796\n",
      "Epoch 332: train loss = 0.0017, val loss = 0.8635\n",
      "Epoch 333: train loss = 0.0017, val loss = 0.8547\n",
      "Epoch 334: train loss = 0.0015, val loss = 0.8560\n",
      "Epoch 335: train loss = 0.0014, val loss = 0.8599\n",
      "Epoch 336: train loss = 0.0014, val loss = 0.8597\n",
      "Epoch 337: train loss = 0.0012, val loss = 0.8589\n",
      "Epoch 338: train loss = 0.0011, val loss = 0.8868\n",
      "Epoch 339: train loss = 0.0011, val loss = 0.8703\n",
      "Epoch 340: train loss = 0.0015, val loss = 0.8558\n",
      "Epoch 341: train loss = 0.0014, val loss = 0.8621\n",
      "Epoch 342: train loss = 0.0011, val loss = 0.8576\n",
      "Epoch 343: train loss = 0.0014, val loss = 0.8506\n",
      "Epoch 344: train loss = 0.0019, val loss = 0.8739\n",
      "Epoch 345: train loss = 0.0015, val loss = 0.8720\n",
      "Epoch 346: train loss = 0.0013, val loss = 0.8582\n",
      "Epoch 347: train loss = 0.0012, val loss = 0.8767\n",
      "Epoch 348: train loss = 0.0015, val loss = 0.8602\n",
      "Epoch 349: train loss = 0.0015, val loss = 0.8776\n",
      "Epoch 350: train loss = 0.0012, val loss = 0.8654\n",
      "Epoch 351: train loss = 0.0013, val loss = 0.8731\n",
      "Epoch 352: train loss = 0.0012, val loss = 0.8581\n",
      "Epoch 353: train loss = 0.0011, val loss = 0.8583\n",
      "Epoch 354: train loss = 0.0012, val loss = 0.8633\n",
      "Epoch 355: train loss = 0.0017, val loss = 0.8610\n",
      "Epoch 356: train loss = 0.0016, val loss = 0.8776\n",
      "Epoch 357: train loss = 0.0018, val loss = 0.8603\n",
      "Epoch 358: train loss = 0.0023, val loss = 0.8678\n",
      "Epoch 359: train loss = 0.0026, val loss = 0.8488\n",
      "Epoch 360: train loss = 0.0028, val loss = 0.8588\n",
      "Epoch 361: train loss = 0.0037, val loss = 0.8566\n",
      "Epoch 362: train loss = 0.0047, val loss = 0.8635\n",
      "Epoch 363: train loss = 0.0076, val loss = 0.8546\n",
      "Epoch 364: train loss = 0.0072, val loss = 0.8916\n",
      "Epoch 365: train loss = 0.0054, val loss = 0.8438\n",
      "Epoch 366: train loss = 0.0061, val loss = 0.8677\n",
      "Epoch 367: train loss = 0.0072, val loss = 0.8458\n",
      "Epoch 368: train loss = 0.0072, val loss = 0.8948\n",
      "Epoch 369: train loss = 0.0072, val loss = 0.8714\n",
      "Epoch 370: train loss = 0.0075, val loss = 0.8449\n",
      "Epoch 371: train loss = 0.0071, val loss = 0.8542\n",
      "Epoch 372: train loss = 0.0076, val loss = 0.8693\n",
      "Epoch 373: train loss = 0.0065, val loss = 0.8461\n",
      "Epoch 374: train loss = 0.0067, val loss = 0.8547\n",
      "Epoch 375: train loss = 0.0070, val loss = 0.8566\n",
      "Epoch 376: train loss = 0.0071, val loss = 0.8701\n",
      "Epoch 377: train loss = 0.0053, val loss = 0.8585\n",
      "Epoch 378: train loss = 0.0042, val loss = 0.8487\n",
      "Epoch 379: train loss = 0.0042, val loss = 0.8616\n",
      "Epoch 380: train loss = 0.0042, val loss = 0.8657\n",
      "Epoch 381: train loss = 0.0035, val loss = 0.8501\n",
      "Epoch 382: train loss = 0.0031, val loss = 0.8823\n",
      "Epoch 383: train loss = 0.0031, val loss = 0.8716\n",
      "Epoch 384: train loss = 0.0029, val loss = 0.8796\n",
      "Epoch 385: train loss = 0.0036, val loss = 0.8674\n",
      "Epoch 386: train loss = 0.0039, val loss = 0.8709\n",
      "Epoch 387: train loss = 0.0045, val loss = 0.8988\n",
      "Epoch 388: train loss = 0.0046, val loss = 0.8779\n",
      "Epoch 389: train loss = 0.0052, val loss = 0.8698\n",
      "Epoch 390: train loss = 0.0067, val loss = 0.8254\n",
      "Epoch 391: train loss = 0.0063, val loss = 0.8593\n",
      "Epoch 392: train loss = 0.0060, val loss = 0.8346\n",
      "Epoch 393: train loss = 0.0058, val loss = 0.8364\n",
      "Epoch 394: train loss = 0.0059, val loss = 0.8420\n",
      "Epoch 395: train loss = 0.0058, val loss = 0.8401\n",
      "Epoch 396: train loss = 0.0073, val loss = 0.8372\n",
      "Epoch 397: train loss = 0.0081, val loss = 0.8063\n",
      "Epoch 398: train loss = 0.0084, val loss = 0.8386\n",
      "Epoch 399: train loss = 0.0077, val loss = 0.8148\n",
      "Epoch 400: train loss = 0.0077, val loss = 0.8247\n",
      "Epoch 401: train loss = 0.0074, val loss = 0.8316\n",
      "Epoch 402: train loss = 0.0096, val loss = 0.8489\n",
      "Epoch 403: train loss = 0.0091, val loss = 0.8467\n",
      "Epoch 404: train loss = 0.0083, val loss = 0.8461\n",
      "Epoch 405: train loss = 0.0087, val loss = 0.8220\n",
      "Epoch 406: train loss = 0.0079, val loss = 0.8372\n",
      "Epoch 407: train loss = 0.0059, val loss = 0.8089\n",
      "Epoch 408: train loss = 0.0040, val loss = 0.8332\n",
      "Epoch 409: train loss = 0.0041, val loss = 0.8293\n",
      "Epoch 410: train loss = 0.0033, val loss = 0.8319\n",
      "Epoch 411: train loss = 0.0041, val loss = 0.8572\n",
      "Epoch 412: train loss = 0.0044, val loss = 0.8263\n",
      "Epoch 413: train loss = 0.0043, val loss = 0.8384\n",
      "Epoch 414: train loss = 0.0042, val loss = 0.8190\n",
      "Epoch 415: train loss = 0.0041, val loss = 0.8289\n",
      "Epoch 416: train loss = 0.0039, val loss = 0.8104\n",
      "Epoch 417: train loss = 0.0058, val loss = 0.8481\n",
      "Epoch 418: train loss = 0.0057, val loss = 0.8224\n",
      "Epoch 419: train loss = 0.0047, val loss = 0.8159\n",
      "Epoch 420: train loss = 0.0044, val loss = 0.8384\n",
      "Epoch 421: train loss = 0.0036, val loss = 0.8430\n",
      "Epoch 422: train loss = 0.0048, val loss = 0.8164\n",
      "Epoch 423: train loss = 0.0047, val loss = 0.8291\n",
      "Epoch 424: train loss = 0.0046, val loss = 0.8260\n",
      "Epoch 425: train loss = 0.0039, val loss = 0.8235\n",
      "Epoch 426: train loss = 0.0036, val loss = 0.8333\n",
      "Epoch 427: train loss = 0.0038, val loss = 0.8192\n",
      "Epoch 428: train loss = 0.0027, val loss = 0.8136\n",
      "Epoch 429: train loss = 0.0027, val loss = 0.8203\n",
      "Epoch 430: train loss = 0.0030, val loss = 0.8220\n",
      "Epoch 431: train loss = 0.0033, val loss = 0.8314\n",
      "Epoch 432: train loss = 0.0040, val loss = 0.8260\n",
      "Epoch 433: train loss = 0.0047, val loss = 0.8152\n",
      "Epoch 434: train loss = 0.0067, val loss = 0.8173\n",
      "Epoch 435: train loss = 0.0053, val loss = 0.8046\n",
      "Epoch 436: train loss = 0.0043, val loss = 0.8320\n",
      "Epoch 437: train loss = 0.0039, val loss = 0.8054\n",
      "Epoch 438: train loss = 0.0037, val loss = 0.8041\n",
      "Epoch 439: train loss = 0.0036, val loss = 0.8126\n",
      "Epoch 440: train loss = 0.0034, val loss = 0.7984\n",
      "Epoch 441: train loss = 0.0037, val loss = 0.8445\n",
      "Epoch 442: train loss = 0.0031, val loss = 0.7857\n",
      "Epoch 443: train loss = 0.0034, val loss = 0.8269\n",
      "Epoch 444: train loss = 0.0035, val loss = 0.7932\n",
      "Epoch 445: train loss = 0.0054, val loss = 0.8247\n",
      "Epoch 446: train loss = 0.0060, val loss = 0.8112\n",
      "Epoch 447: train loss = 0.0056, val loss = 0.8650\n",
      "Epoch 448: train loss = 0.0070, val loss = 0.7864\n",
      "Epoch 449: train loss = 0.0064, val loss = 0.8281\n",
      "Epoch 450: train loss = 0.0062, val loss = 0.8450\n",
      "Epoch 451: train loss = 0.0054, val loss = 0.8074\n",
      "Epoch 452: train loss = 0.0061, val loss = 0.8407\n",
      "Epoch 453: train loss = 0.0088, val loss = 0.8503\n",
      "Epoch 454: train loss = 0.0100, val loss = 0.7922\n",
      "Epoch 455: train loss = 0.0090, val loss = 0.8244\n",
      "Epoch 456: train loss = 0.0113, val loss = 0.8294\n",
      "Epoch 457: train loss = 0.0088, val loss = 0.8055\n",
      "Epoch 458: train loss = 0.0070, val loss = 0.8336\n",
      "Epoch 459: train loss = 0.0057, val loss = 0.7985\n",
      "Epoch 460: train loss = 0.0046, val loss = 0.7844\n",
      "Epoch 461: train loss = 0.0042, val loss = 0.8023\n",
      "Epoch 462: train loss = 0.0042, val loss = 0.8155\n",
      "Epoch 463: train loss = 0.0049, val loss = 0.8226\n",
      "Epoch 464: train loss = 0.0050, val loss = 0.8218\n",
      "Epoch 465: train loss = 0.0058, val loss = 0.7741\n",
      "Epoch 466: train loss = 0.0073, val loss = 0.7832\n",
      "Epoch 467: train loss = 0.0071, val loss = 0.7848\n",
      "Epoch 468: train loss = 0.0066, val loss = 0.8019\n",
      "Epoch 469: train loss = 0.0051, val loss = 0.8090\n",
      "Epoch 470: train loss = 0.0056, val loss = 0.7634\n",
      "Epoch 471: train loss = 0.0050, val loss = 0.7862\n",
      "Epoch 472: train loss = 0.0042, val loss = 0.7776\n",
      "Epoch 473: train loss = 0.0042, val loss = 0.7757\n",
      "Epoch 474: train loss = 0.0036, val loss = 0.7833\n",
      "Epoch 475: train loss = 0.0026, val loss = 0.7877\n",
      "Epoch 476: train loss = 0.0021, val loss = 0.7835\n",
      "Epoch 477: train loss = 0.0022, val loss = 0.7953\n",
      "Epoch 478: train loss = 0.0025, val loss = 0.8191\n",
      "Epoch 479: train loss = 0.0020, val loss = 0.7846\n",
      "Epoch 480: train loss = 0.0022, val loss = 0.8078\n",
      "Epoch 481: train loss = 0.0017, val loss = 0.8000\n",
      "Epoch 482: train loss = 0.0015, val loss = 0.7974\n",
      "Epoch 483: train loss = 0.0018, val loss = 0.8028\n",
      "Epoch 484: train loss = 0.0017, val loss = 0.7912\n",
      "Epoch 485: train loss = 0.0015, val loss = 0.7846\n",
      "Epoch 486: train loss = 0.0011, val loss = 0.7860\n",
      "Epoch 487: train loss = 0.0009, val loss = 0.7797\n",
      "Epoch 488: train loss = 0.0012, val loss = 0.7762\n",
      "Epoch 489: train loss = 0.0014, val loss = 0.7832\n",
      "Epoch 490: train loss = 0.0014, val loss = 0.7887\n",
      "Epoch 491: train loss = 0.0011, val loss = 0.7759\n",
      "Epoch 492: train loss = 0.0013, val loss = 0.7798\n",
      "Epoch 493: train loss = 0.0016, val loss = 0.7868\n",
      "Epoch 494: train loss = 0.0014, val loss = 0.7944\n",
      "Epoch 495: train loss = 0.0013, val loss = 0.7676\n",
      "Epoch 496: train loss = 0.0011, val loss = 0.7960\n",
      "Epoch 497: train loss = 0.0013, val loss = 0.7687\n",
      "Epoch 498: train loss = 0.0016, val loss = 0.7899\n",
      "Epoch 499: train loss = 0.0015, val loss = 0.8027\n",
      "Epoch 500: train loss = 0.0013, val loss = 0.7845\n",
      "Epoch 501: train loss = 0.0013, val loss = 0.7798\n",
      "Epoch 502: train loss = 0.0014, val loss = 0.7829\n",
      "Epoch 503: train loss = 0.0016, val loss = 0.7874\n",
      "Epoch 504: train loss = 0.0016, val loss = 0.7890\n",
      "Epoch 505: train loss = 0.0013, val loss = 0.7935\n",
      "Epoch 506: train loss = 0.0019, val loss = 0.7910\n",
      "Epoch 507: train loss = 0.0019, val loss = 0.7731\n",
      "Epoch 508: train loss = 0.0026, val loss = 0.7608\n",
      "Epoch 509: train loss = 0.0033, val loss = 0.7623\n",
      "Epoch 510: train loss = 0.0040, val loss = 0.7761\n",
      "Epoch 511: train loss = 0.0041, val loss = 0.7935\n",
      "Epoch 512: train loss = 0.0041, val loss = 0.7735\n",
      "Epoch 513: train loss = 0.0043, val loss = 0.7796\n",
      "Epoch 514: train loss = 0.0044, val loss = 0.7834\n",
      "Epoch 515: train loss = 0.0035, val loss = 0.7986\n",
      "Epoch 516: train loss = 0.0029, val loss = 0.7982\n",
      "Epoch 517: train loss = 0.0024, val loss = 0.7734\n",
      "Epoch 518: train loss = 0.0028, val loss = 0.7788\n",
      "Epoch 519: train loss = 0.0030, val loss = 0.7841\n",
      "Epoch 520: train loss = 0.0038, val loss = 0.7851\n",
      "Epoch 521: train loss = 0.0044, val loss = 0.8065\n",
      "Epoch 522: train loss = 0.0051, val loss = 0.7954\n",
      "Epoch 523: train loss = 0.0050, val loss = 0.7651\n",
      "Epoch 524: train loss = 0.0063, val loss = 0.8316\n",
      "Epoch 525: train loss = 0.0081, val loss = 0.7993\n",
      "Epoch 526: train loss = 0.0089, val loss = 0.7330\n",
      "Epoch 527: train loss = 0.0088, val loss = 0.7808\n",
      "Epoch 528: train loss = 0.0087, val loss = 0.8316\n",
      "Epoch 529: train loss = 0.0083, val loss = 0.7467\n",
      "Epoch 530: train loss = 0.0087, val loss = 0.7858\n",
      "Epoch 531: train loss = 0.0066, val loss = 0.7851\n",
      "Epoch 532: train loss = 0.0065, val loss = 0.8038\n",
      "Epoch 533: train loss = 0.0075, val loss = 0.7920\n",
      "Epoch 534: train loss = 0.0091, val loss = 0.7812\n",
      "Epoch 535: train loss = 0.0116, val loss = 0.7796\n",
      "Epoch 536: train loss = 0.0083, val loss = 0.7860\n",
      "Epoch 537: train loss = 0.0069, val loss = 0.7849\n",
      "Epoch 538: train loss = 0.0072, val loss = 0.7759\n",
      "Epoch 539: train loss = 0.0086, val loss = 0.8048\n",
      "Epoch 540: train loss = 0.0081, val loss = 0.8239\n",
      "Epoch 541: train loss = 0.0064, val loss = 0.8116\n",
      "Epoch 542: train loss = 0.0050, val loss = 0.8012\n",
      "Epoch 543: train loss = 0.0045, val loss = 0.7985\n",
      "Epoch 544: train loss = 0.0033, val loss = 0.8225\n",
      "Epoch 545: train loss = 0.0034, val loss = 0.7871\n",
      "Epoch 546: train loss = 0.0033, val loss = 0.7976\n",
      "Epoch 547: train loss = 0.0026, val loss = 0.7697\n",
      "Epoch 548: train loss = 0.0025, val loss = 0.7784\n",
      "Epoch 549: train loss = 0.0033, val loss = 0.7814\n",
      "Epoch 550: train loss = 0.0041, val loss = 0.7950\n",
      "Epoch 551: train loss = 0.0038, val loss = 0.7929\n",
      "Epoch 552: train loss = 0.0037, val loss = 0.7939\n",
      "Epoch 553: train loss = 0.0045, val loss = 0.8062\n",
      "Epoch 554: train loss = 0.0052, val loss = 0.7955\n",
      "Epoch 555: train loss = 0.0039, val loss = 0.7883\n",
      "Epoch 556: train loss = 0.0025, val loss = 0.7819\n",
      "Epoch 557: train loss = 0.0021, val loss = 0.8143\n",
      "Epoch 558: train loss = 0.0016, val loss = 0.7844\n",
      "Epoch 559: train loss = 0.0015, val loss = 0.8052\n",
      "Epoch 560: train loss = 0.0013, val loss = 0.8067\n",
      "Epoch 561: train loss = 0.0014, val loss = 0.7938\n",
      "Epoch 562: train loss = 0.0014, val loss = 0.7888\n",
      "Epoch 563: train loss = 0.0011, val loss = 0.8007\n",
      "Epoch 564: train loss = 0.0012, val loss = 0.8018\n",
      "Epoch 565: train loss = 0.0012, val loss = 0.7791\n",
      "Epoch 566: train loss = 0.0016, val loss = 0.8049\n",
      "Epoch 567: train loss = 0.0015, val loss = 0.7901\n",
      "Epoch 568: train loss = 0.0012, val loss = 0.7981\n",
      "Epoch 569: train loss = 0.0013, val loss = 0.7705\n",
      "Epoch 570: train loss = 0.0011, val loss = 0.7890\n",
      "Epoch 571: train loss = 0.0010, val loss = 0.7887\n",
      "Epoch 572: train loss = 0.0010, val loss = 0.7708\n",
      "Epoch 573: train loss = 0.0008, val loss = 0.7790\n",
      "Epoch 574: train loss = 0.0010, val loss = 0.7857\n",
      "Epoch 575: train loss = 0.0009, val loss = 0.8033\n",
      "Epoch 576: train loss = 0.0008, val loss = 0.7828\n",
      "Epoch 577: train loss = 0.0009, val loss = 0.7866\n",
      "Epoch 578: train loss = 0.0011, val loss = 0.7861\n",
      "Epoch 579: train loss = 0.0010, val loss = 0.8058\n",
      "Epoch 580: train loss = 0.0013, val loss = 0.7808\n",
      "Epoch 581: train loss = 0.0017, val loss = 0.8181\n",
      "Epoch 582: train loss = 0.0017, val loss = 0.7947\n",
      "Epoch 583: train loss = 0.0021, val loss = 0.7795\n",
      "Epoch 584: train loss = 0.0024, val loss = 0.7862\n",
      "Epoch 585: train loss = 0.0026, val loss = 0.7897\n",
      "Epoch 586: train loss = 0.0032, val loss = 0.7759\n",
      "Epoch 587: train loss = 0.0044, val loss = 0.8148\n",
      "Epoch 588: train loss = 0.0055, val loss = 0.7912\n",
      "Epoch 589: train loss = 0.0050, val loss = 0.7897\n",
      "Epoch 590: train loss = 0.0064, val loss = 0.8214\n",
      "Epoch 591: train loss = 0.0064, val loss = 0.7680\n",
      "Epoch 592: train loss = 0.0059, val loss = 0.8034\n",
      "Epoch 593: train loss = 0.0055, val loss = 0.7685\n",
      "Epoch 594: train loss = 0.0056, val loss = 0.8201\n",
      "Epoch 595: train loss = 0.0061, val loss = 0.7504\n",
      "Epoch 596: train loss = 0.0058, val loss = 0.7949\n",
      "Epoch 597: train loss = 0.0066, val loss = 0.7786\n",
      "Epoch 598: train loss = 0.0056, val loss = 0.7748\n",
      "Epoch 599: train loss = 0.0064, val loss = 0.7458\n",
      "Epoch 600: train loss = 0.0067, val loss = 0.7982\n",
      "Epoch 601: train loss = 0.0078, val loss = 0.7438\n",
      "Epoch 602: train loss = 0.0077, val loss = 0.7720\n",
      "Epoch 603: train loss = 0.0077, val loss = 0.7852\n",
      "Epoch 604: train loss = 0.0073, val loss = 0.7903\n",
      "Epoch 605: train loss = 0.0076, val loss = 0.7481\n",
      "Epoch 606: train loss = 0.0079, val loss = 0.7442\n",
      "Epoch 607: train loss = 0.0057, val loss = 0.7830\n",
      "Epoch 608: train loss = 0.0046, val loss = 0.7978\n",
      "Epoch 609: train loss = 0.0069, val loss = 0.8206\n",
      "Epoch 610: train loss = 0.0073, val loss = 0.7379\n",
      "Epoch 611: train loss = 0.0057, val loss = 0.7400\n",
      "Epoch 612: train loss = 0.0041, val loss = 0.7761\n",
      "Epoch 613: train loss = 0.0028, val loss = 0.7816\n",
      "Epoch 614: train loss = 0.0023, val loss = 0.7815\n",
      "Epoch 615: train loss = 0.0018, val loss = 0.7693\n",
      "Epoch 616: train loss = 0.0016, val loss = 0.7687\n",
      "Epoch 617: train loss = 0.0013, val loss = 0.7561\n",
      "Epoch 618: train loss = 0.0009, val loss = 0.7709\n",
      "Epoch 619: train loss = 0.0007, val loss = 0.7715\n",
      "Epoch 620: train loss = 0.0008, val loss = 0.7666\n",
      "Epoch 621: train loss = 0.0006, val loss = 0.7740\n",
      "Epoch 622: train loss = 0.0006, val loss = 0.7625\n",
      "Epoch 623: train loss = 0.0005, val loss = 0.7821\n",
      "Epoch 624: train loss = 0.0006, val loss = 0.7661\n",
      "Epoch 625: train loss = 0.0005, val loss = 0.7719\n",
      "Epoch 626: train loss = 0.0006, val loss = 0.7927\n",
      "Epoch 627: train loss = 0.0011, val loss = 0.7760\n",
      "Epoch 628: train loss = 0.0011, val loss = 0.7727\n",
      "Epoch 629: train loss = 0.0014, val loss = 0.7839\n",
      "Epoch 630: train loss = 0.0019, val loss = 0.7533\n",
      "Epoch 631: train loss = 0.0016, val loss = 0.7713\n",
      "Epoch 632: train loss = 0.0014, val loss = 0.7791\n",
      "Epoch 633: train loss = 0.0010, val loss = 0.7660\n",
      "Epoch 634: train loss = 0.0010, val loss = 0.7710\n",
      "Epoch 635: train loss = 0.0010, val loss = 0.7754\n",
      "Epoch 636: train loss = 0.0010, val loss = 0.7737\n",
      "Epoch 637: train loss = 0.0008, val loss = 0.7788\n",
      "Epoch 638: train loss = 0.0008, val loss = 0.7633\n",
      "Epoch 639: train loss = 0.0006, val loss = 0.7773\n",
      "Epoch 640: train loss = 0.0008, val loss = 0.7574\n",
      "Epoch 641: train loss = 0.0016, val loss = 0.7906\n",
      "Epoch 642: train loss = 0.0018, val loss = 0.7888\n",
      "Epoch 643: train loss = 0.0026, val loss = 0.7869\n",
      "Epoch 644: train loss = 0.0024, val loss = 0.7628\n",
      "Epoch 645: train loss = 0.0027, val loss = 0.7753\n",
      "Epoch 646: train loss = 0.0024, val loss = 0.7519\n",
      "Epoch 647: train loss = 0.0034, val loss = 0.7978\n",
      "Epoch 648: train loss = 0.0033, val loss = 0.7570\n",
      "Epoch 649: train loss = 0.0030, val loss = 0.7638\n",
      "Epoch 650: train loss = 0.0029, val loss = 0.7672\n",
      "Epoch 651: train loss = 0.0037, val loss = 0.8173\n",
      "Epoch 652: train loss = 0.0047, val loss = 0.7746\n",
      "Epoch 653: train loss = 0.0043, val loss = 0.7603\n",
      "Epoch 654: train loss = 0.0043, val loss = 0.7949\n",
      "Epoch 655: train loss = 0.0041, val loss = 0.7540\n",
      "Epoch 656: train loss = 0.0029, val loss = 0.7943\n",
      "Epoch 657: train loss = 0.0026, val loss = 0.7635\n",
      "Epoch 658: train loss = 0.0028, val loss = 0.7963\n",
      "Epoch 659: train loss = 0.0030, val loss = 0.7520\n",
      "Epoch 660: train loss = 0.0104, val loss = 0.7491\n",
      "Epoch 661: train loss = 0.0123, val loss = 0.7652\n",
      "Epoch 662: train loss = 0.0190, val loss = 0.7661\n",
      "Epoch 663: train loss = 0.0249, val loss = 0.7506\n",
      "Epoch 664: train loss = 0.0358, val loss = 0.7635\n",
      "Epoch 665: train loss = 0.0230, val loss = 0.7347\n",
      "Epoch 666: train loss = 0.0199, val loss = 0.8048\n",
      "Epoch 667: train loss = 0.0124, val loss = 0.8117\n",
      "Epoch 668: train loss = 0.0087, val loss = 0.8076\n",
      "Epoch 669: train loss = 0.0062, val loss = 0.7929\n",
      "Epoch 670: train loss = 0.0044, val loss = 0.8198\n",
      "Epoch 671: train loss = 0.0032, val loss = 0.8062\n",
      "Epoch 672: train loss = 0.0020, val loss = 0.8011\n",
      "Epoch 673: train loss = 0.0013, val loss = 0.8123\n",
      "Epoch 674: train loss = 0.0014, val loss = 0.7900\n",
      "Epoch 675: train loss = 0.0016, val loss = 0.8206\n",
      "Epoch 676: train loss = 0.0018, val loss = 0.8095\n",
      "Epoch 677: train loss = 0.0017, val loss = 0.8009\n",
      "Epoch 678: train loss = 0.0011, val loss = 0.7970\n",
      "Epoch 679: train loss = 0.0008, val loss = 0.7915\n",
      "Epoch 680: train loss = 0.0007, val loss = 0.7875\n",
      "Epoch 681: train loss = 0.0005, val loss = 0.8009\n",
      "Epoch 682: train loss = 0.0003, val loss = 0.7927\n",
      "Epoch 683: train loss = 0.0003, val loss = 0.7974\n",
      "Epoch 684: train loss = 0.0003, val loss = 0.7955\n",
      "Epoch 685: train loss = 0.0002, val loss = 0.7978\n",
      "Epoch 686: train loss = 0.0001, val loss = 0.7975\n",
      "Epoch 687: train loss = 0.0001, val loss = 0.7959\n",
      "Epoch 688: train loss = 0.0001, val loss = 0.7989\n",
      "Epoch 689: train loss = 0.0001, val loss = 0.7955\n",
      "Epoch 690: train loss = 0.0001, val loss = 0.7983\n",
      "Epoch 691: train loss = 0.0000, val loss = 0.7955\n",
      "Epoch 692: train loss = 0.0000, val loss = 0.7952\n",
      "Epoch 693: train loss = 0.0000, val loss = 0.7995\n",
      "Epoch 694: train loss = 0.0000, val loss = 0.7970\n",
      "Epoch 695: train loss = 0.0000, val loss = 0.7969\n",
      "Epoch 696: train loss = 0.0000, val loss = 0.7966\n",
      "Epoch 697: train loss = 0.0000, val loss = 0.7977\n",
      "Epoch 698: train loss = 0.0000, val loss = 0.7988\n",
      "Epoch 699: train loss = 0.0000, val loss = 0.7969\n",
      "Epoch 700: train loss = 0.0000, val loss = 0.7962\n",
      "Epoch 701: train loss = 0.0000, val loss = 0.7966\n",
      "Epoch 702: train loss = 0.0000, val loss = 0.7976\n",
      "Epoch 703: train loss = 0.0000, val loss = 0.7975\n",
      "Epoch 704: train loss = 0.0000, val loss = 0.7968\n",
      "Epoch 705: train loss = 0.0000, val loss = 0.7981\n",
      "Epoch 706: train loss = 0.0000, val loss = 0.7965\n",
      "Epoch 707: train loss = 0.0000, val loss = 0.7991\n",
      "Epoch 708: train loss = 0.0000, val loss = 0.7972\n",
      "Epoch 709: train loss = 0.0000, val loss = 0.7963\n",
      "Epoch 710: train loss = 0.0000, val loss = 0.8000\n",
      "Epoch 711: train loss = 0.0000, val loss = 0.7977\n",
      "Epoch 712: train loss = 0.0000, val loss = 0.7982\n",
      "Epoch 713: train loss = 0.0000, val loss = 0.7936\n",
      "Epoch 714: train loss = 0.0001, val loss = 0.7942\n",
      "Epoch 715: train loss = 0.0001, val loss = 0.7988\n",
      "Epoch 716: train loss = 0.0001, val loss = 0.7955\n",
      "Epoch 717: train loss = 0.0001, val loss = 0.7989\n",
      "Epoch 718: train loss = 0.0001, val loss = 0.7939\n",
      "Epoch 719: train loss = 0.0001, val loss = 0.7998\n",
      "Epoch 720: train loss = 0.0001, val loss = 0.7995\n",
      "Epoch 721: train loss = 0.0001, val loss = 0.7996\n",
      "Epoch 722: train loss = 0.0001, val loss = 0.8019\n",
      "Epoch 723: train loss = 0.0002, val loss = 0.7962\n",
      "Epoch 724: train loss = 0.0002, val loss = 0.7974\n",
      "Epoch 725: train loss = 0.0003, val loss = 0.7996\n",
      "Epoch 726: train loss = 0.0002, val loss = 0.7918\n",
      "Epoch 727: train loss = 0.0003, val loss = 0.7929\n",
      "Epoch 728: train loss = 0.0003, val loss = 0.8002\n",
      "Epoch 729: train loss = 0.0004, val loss = 0.7950\n",
      "Epoch 730: train loss = 0.0006, val loss = 0.7971\n",
      "Epoch 731: train loss = 0.0006, val loss = 0.7981\n",
      "Epoch 732: train loss = 0.0007, val loss = 0.7971\n",
      "Epoch 733: train loss = 0.0012, val loss = 0.8111\n",
      "Epoch 734: train loss = 0.0015, val loss = 0.7824\n",
      "Epoch 735: train loss = 0.0031, val loss = 0.7947\n",
      "Epoch 736: train loss = 0.0034, val loss = 0.7873\n",
      "Epoch 737: train loss = 0.0051, val loss = 0.8125\n",
      "Epoch 738: train loss = 0.0048, val loss = 0.7740\n",
      "Epoch 739: train loss = 0.0048, val loss = 0.7948\n",
      "Epoch 740: train loss = 0.0058, val loss = 0.8154\n",
      "Epoch 741: train loss = 0.0070, val loss = 0.8078\n",
      "Epoch 742: train loss = 0.0072, val loss = 0.8246\n",
      "Epoch 743: train loss = 0.0081, val loss = 0.8001\n",
      "Epoch 744: train loss = 0.0072, val loss = 0.7571\n",
      "Epoch 745: train loss = 0.0106, val loss = 0.7905\n",
      "Epoch 746: train loss = 0.0127, val loss = 0.8380\n",
      "Epoch 747: train loss = 0.0135, val loss = 0.8059\n",
      "Epoch 748: train loss = 0.0108, val loss = 0.7973\n",
      "Epoch 749: train loss = 0.0101, val loss = 0.7524\n",
      "Epoch 750: train loss = 0.0077, val loss = 0.8179\n",
      "Epoch 751: train loss = 0.0065, val loss = 0.8041\n",
      "Epoch 752: train loss = 0.0049, val loss = 0.7888\n",
      "Epoch 753: train loss = 0.0055, val loss = 0.8477\n",
      "Epoch 754: train loss = 0.0045, val loss = 0.8218\n",
      "Epoch 755: train loss = 0.0063, val loss = 0.8133\n",
      "Epoch 756: train loss = 0.0049, val loss = 0.8065\n",
      "Epoch 757: train loss = 0.0046, val loss = 0.7815\n",
      "Epoch 758: train loss = 0.0030, val loss = 0.7886\n",
      "Epoch 759: train loss = 0.0030, val loss = 0.8079\n",
      "Epoch 760: train loss = 0.0024, val loss = 0.7876\n",
      "Epoch 761: train loss = 0.0019, val loss = 0.7824\n",
      "Epoch 762: train loss = 0.0017, val loss = 0.7973\n",
      "Epoch 763: train loss = 0.0017, val loss = 0.8194\n",
      "Epoch 764: train loss = 0.0020, val loss = 0.8048\n",
      "Epoch 765: train loss = 0.0015, val loss = 0.7901\n",
      "Epoch 766: train loss = 0.0020, val loss = 0.7948\n",
      "Epoch 767: train loss = 0.0016, val loss = 0.8045\n",
      "Epoch 768: train loss = 0.0014, val loss = 0.7871\n",
      "Epoch 769: train loss = 0.0012, val loss = 0.7954\n",
      "Epoch 770: train loss = 0.0008, val loss = 0.7925\n",
      "Epoch 771: train loss = 0.0007, val loss = 0.7795\n",
      "Epoch 772: train loss = 0.0006, val loss = 0.8091\n",
      "Epoch 773: train loss = 0.0004, val loss = 0.7905\n",
      "Epoch 774: train loss = 0.0004, val loss = 0.7998\n",
      "Epoch 775: train loss = 0.0005, val loss = 0.7955\n",
      "Epoch 776: train loss = 0.0004, val loss = 0.7858\n",
      "Epoch 777: train loss = 0.0003, val loss = 0.7860\n",
      "Epoch 778: train loss = 0.0003, val loss = 0.7918\n",
      "Epoch 779: train loss = 0.0003, val loss = 0.8054\n",
      "Epoch 780: train loss = 0.0002, val loss = 0.8072\n",
      "Epoch 781: train loss = 0.0002, val loss = 0.8004\n",
      "Epoch 782: train loss = 0.0003, val loss = 0.8105\n",
      "Epoch 783: train loss = 0.0003, val loss = 0.8100\n",
      "Epoch 784: train loss = 0.0003, val loss = 0.7888\n",
      "Epoch 785: train loss = 0.0003, val loss = 0.8005\n",
      "Epoch 786: train loss = 0.0003, val loss = 0.8127\n",
      "Epoch 787: train loss = 0.0004, val loss = 0.8012\n",
      "Epoch 788: train loss = 0.0003, val loss = 0.7956\n",
      "Epoch 789: train loss = 0.0003, val loss = 0.7857\n",
      "Epoch 790: train loss = 0.0003, val loss = 0.7904\n",
      "Epoch 791: train loss = 0.0004, val loss = 0.7852\n",
      "Epoch 792: train loss = 0.0006, val loss = 0.8036\n",
      "Epoch 793: train loss = 0.0006, val loss = 0.7974\n",
      "Epoch 794: train loss = 0.0006, val loss = 0.7752\n",
      "Epoch 795: train loss = 0.0004, val loss = 0.7907\n",
      "Epoch 796: train loss = 0.0006, val loss = 0.7803\n",
      "Epoch 797: train loss = 0.0007, val loss = 0.7960\n",
      "Epoch 798: train loss = 0.0007, val loss = 0.7981\n",
      "Epoch 799: train loss = 0.0007, val loss = 0.7953\n",
      "Epoch 800: train loss = 0.0006, val loss = 0.7919\n",
      "Epoch 801: train loss = 0.0010, val loss = 0.7968\n",
      "Epoch 802: train loss = 0.0013, val loss = 0.7906\n",
      "Epoch 803: train loss = 0.0016, val loss = 0.8185\n",
      "Epoch 804: train loss = 0.0022, val loss = 0.7870\n",
      "Epoch 805: train loss = 0.0025, val loss = 0.7649\n",
      "Epoch 806: train loss = 0.0052, val loss = 0.7802\n",
      "Epoch 807: train loss = 0.0073, val loss = 0.7953\n",
      "Epoch 808: train loss = 0.0064, val loss = 0.7684\n",
      "Epoch 809: train loss = 0.0068, val loss = 0.8219\n",
      "Epoch 810: train loss = 0.0070, val loss = 0.7685\n",
      "Epoch 811: train loss = 0.0071, val loss = 0.8387\n",
      "Epoch 812: train loss = 0.0055, val loss = 0.7847\n",
      "Epoch 813: train loss = 0.0046, val loss = 0.7772\n",
      "Epoch 814: train loss = 0.0041, val loss = 0.7941\n",
      "Epoch 815: train loss = 0.0031, val loss = 0.8144\n",
      "Epoch 816: train loss = 0.0037, val loss = 0.7897\n",
      "Epoch 817: train loss = 0.0027, val loss = 0.7455\n",
      "Epoch 818: train loss = 0.0025, val loss = 0.7706\n",
      "Epoch 819: train loss = 0.0026, val loss = 0.7921\n",
      "Epoch 820: train loss = 0.0029, val loss = 0.7447\n",
      "Epoch 821: train loss = 0.0037, val loss = 0.7941\n",
      "Epoch 822: train loss = 0.0031, val loss = 0.7904\n",
      "Epoch 823: train loss = 0.0026, val loss = 0.7814\n",
      "Epoch 824: train loss = 0.0033, val loss = 0.7998\n",
      "Epoch 825: train loss = 0.0029, val loss = 0.7985\n",
      "Epoch 826: train loss = 0.0021, val loss = 0.8217\n",
      "Epoch 827: train loss = 0.0026, val loss = 0.8101\n",
      "Epoch 828: train loss = 0.0023, val loss = 0.8119\n",
      "Epoch 829: train loss = 0.0020, val loss = 0.7807\n",
      "Epoch 830: train loss = 0.0019, val loss = 0.7917\n",
      "Epoch 831: train loss = 0.0020, val loss = 0.7757\n",
      "Epoch 832: train loss = 0.0016, val loss = 0.8009\n",
      "Epoch 833: train loss = 0.0019, val loss = 0.7920\n",
      "Epoch 834: train loss = 0.0023, val loss = 0.7722\n",
      "Epoch 835: train loss = 0.0019, val loss = 0.7680\n",
      "Epoch 836: train loss = 0.0022, val loss = 0.8017\n",
      "Epoch 837: train loss = 0.0033, val loss = 0.8157\n",
      "Epoch 838: train loss = 0.0050, val loss = 0.7623\n",
      "Epoch 839: train loss = 0.0060, val loss = 0.8273\n",
      "Epoch 840: train loss = 0.0062, val loss = 0.7988\n",
      "Epoch 841: train loss = 0.0042, val loss = 0.8043\n",
      "Epoch 842: train loss = 0.0038, val loss = 0.7732\n",
      "Epoch 843: train loss = 0.0030, val loss = 0.7580\n",
      "Epoch 844: train loss = 0.0025, val loss = 0.7730\n",
      "Epoch 845: train loss = 0.0018, val loss = 0.7803\n",
      "Epoch 846: train loss = 0.0013, val loss = 0.7828\n",
      "Epoch 847: train loss = 0.0012, val loss = 0.7980\n",
      "Epoch 848: train loss = 0.0009, val loss = 0.8112\n",
      "Epoch 849: train loss = 0.0008, val loss = 0.7872\n",
      "Epoch 850: train loss = 0.0009, val loss = 0.8034\n",
      "Epoch 851: train loss = 0.0015, val loss = 0.7917\n",
      "Epoch 852: train loss = 0.0017, val loss = 0.8022\n",
      "Epoch 853: train loss = 0.0026, val loss = 0.7744\n",
      "Epoch 854: train loss = 0.0030, val loss = 0.7734\n",
      "Epoch 855: train loss = 0.0043, val loss = 0.7615\n",
      "Epoch 856: train loss = 0.0039, val loss = 0.7573\n",
      "Epoch 857: train loss = 0.0037, val loss = 0.7828\n",
      "Epoch 858: train loss = 0.0029, val loss = 0.8022\n",
      "Epoch 859: train loss = 0.0023, val loss = 0.7900\n",
      "Epoch 860: train loss = 0.0026, val loss = 0.7795\n",
      "Epoch 861: train loss = 0.0023, val loss = 0.7857\n",
      "Epoch 862: train loss = 0.0020, val loss = 0.7718\n",
      "Epoch 863: train loss = 0.0022, val loss = 0.7896\n",
      "Epoch 864: train loss = 0.0028, val loss = 0.8358\n",
      "Epoch 865: train loss = 0.0050, val loss = 0.7917\n",
      "Epoch 866: train loss = 0.0046, val loss = 0.8158\n",
      "Epoch 867: train loss = 0.0050, val loss = 0.7927\n",
      "Epoch 868: train loss = 0.0057, val loss = 0.8139\n",
      "Epoch 869: train loss = 0.0044, val loss = 0.8282\n",
      "Epoch 870: train loss = 0.0048, val loss = 0.7897\n",
      "Epoch 871: train loss = 0.0045, val loss = 0.7989\n",
      "Epoch 872: train loss = 0.0050, val loss = 0.7860\n",
      "Epoch 873: train loss = 0.0047, val loss = 0.8244\n",
      "Epoch 874: train loss = 0.0039, val loss = 0.8352\n",
      "Epoch 875: train loss = 0.0049, val loss = 0.7825\n",
      "Epoch 876: train loss = 0.0038, val loss = 0.7618\n",
      "Epoch 877: train loss = 0.0029, val loss = 0.7682\n",
      "Epoch 878: train loss = 0.0024, val loss = 0.8035\n",
      "Epoch 879: train loss = 0.0026, val loss = 0.7673\n",
      "Epoch 880: train loss = 0.0020, val loss = 0.7862\n",
      "Epoch 881: train loss = 0.0023, val loss = 0.7934\n",
      "Epoch 882: train loss = 0.0020, val loss = 0.7744\n",
      "Epoch 883: train loss = 0.0013, val loss = 0.7816\n",
      "Epoch 884: train loss = 0.0009, val loss = 0.7912\n",
      "Epoch 885: train loss = 0.0009, val loss = 0.7917\n",
      "Epoch 886: train loss = 0.0008, val loss = 0.7874\n",
      "Epoch 887: train loss = 0.0006, val loss = 0.7790\n",
      "Epoch 888: train loss = 0.0006, val loss = 0.7831\n",
      "Epoch 889: train loss = 0.0005, val loss = 0.7831\n",
      "Epoch 890: train loss = 0.0005, val loss = 0.7924\n",
      "Epoch 891: train loss = 0.0004, val loss = 0.7868\n",
      "Epoch 892: train loss = 0.0003, val loss = 0.7718\n",
      "Epoch 893: train loss = 0.0006, val loss = 0.7882\n",
      "Epoch 894: train loss = 0.0008, val loss = 0.8069\n",
      "Epoch 895: train loss = 0.0009, val loss = 0.7938\n",
      "Epoch 896: train loss = 0.0007, val loss = 0.7795\n",
      "Epoch 897: train loss = 0.0006, val loss = 0.7859\n",
      "Epoch 898: train loss = 0.0005, val loss = 0.7927\n",
      "Epoch 899: train loss = 0.0006, val loss = 0.7778\n",
      "Epoch 900: train loss = 0.0008, val loss = 0.8071\n",
      "Epoch 901: train loss = 0.0007, val loss = 0.7774\n",
      "Epoch 902: train loss = 0.0012, val loss = 0.7857\n",
      "Epoch 903: train loss = 0.0013, val loss = 0.7834\n",
      "Epoch 904: train loss = 0.0011, val loss = 0.7877\n",
      "Epoch 905: train loss = 0.0010, val loss = 0.7957\n",
      "Epoch 906: train loss = 0.0009, val loss = 0.7788\n",
      "Epoch 907: train loss = 0.0009, val loss = 0.7790\n",
      "Epoch 908: train loss = 0.0009, val loss = 0.7990\n",
      "Epoch 909: train loss = 0.0008, val loss = 0.7771\n",
      "Epoch 910: train loss = 0.0007, val loss = 0.7856\n",
      "Epoch 911: train loss = 0.0007, val loss = 0.7705\n",
      "Epoch 912: train loss = 0.0008, val loss = 0.7784\n",
      "Epoch 913: train loss = 0.0010, val loss = 0.8130\n",
      "Epoch 914: train loss = 0.0015, val loss = 0.7933\n",
      "Epoch 915: train loss = 0.0018, val loss = 0.7825\n",
      "Epoch 916: train loss = 0.0024, val loss = 0.8185\n",
      "Epoch 917: train loss = 0.0021, val loss = 0.7839\n",
      "Epoch 918: train loss = 0.0020, val loss = 0.7998\n",
      "Epoch 919: train loss = 0.0022, val loss = 0.8048\n",
      "Epoch 920: train loss = 0.0024, val loss = 0.7798\n",
      "Epoch 921: train loss = 0.0025, val loss = 0.8054\n",
      "Epoch 922: train loss = 0.0021, val loss = 0.7703\n",
      "Epoch 923: train loss = 0.0019, val loss = 0.7948\n",
      "Epoch 924: train loss = 0.0017, val loss = 0.7617\n",
      "Epoch 925: train loss = 0.0025, val loss = 0.7865\n",
      "Epoch 926: train loss = 0.0018, val loss = 0.7835\n",
      "Epoch 927: train loss = 0.0018, val loss = 0.8036\n",
      "Epoch 928: train loss = 0.0014, val loss = 0.8100\n",
      "Epoch 929: train loss = 0.0014, val loss = 0.7736\n",
      "Epoch 930: train loss = 0.0014, val loss = 0.8087\n",
      "Epoch 931: train loss = 0.0019, val loss = 0.7720\n",
      "Epoch 932: train loss = 0.0022, val loss = 0.8283\n",
      "Epoch 933: train loss = 0.0028, val loss = 0.7650\n",
      "Epoch 934: train loss = 0.0037, val loss = 0.8362\n",
      "Epoch 935: train loss = 0.0032, val loss = 0.8068\n",
      "Epoch 936: train loss = 0.0028, val loss = 0.8123\n",
      "Epoch 937: train loss = 0.0023, val loss = 0.7993\n",
      "Epoch 938: train loss = 0.0019, val loss = 0.8010\n",
      "Epoch 939: train loss = 0.0020, val loss = 0.8130\n",
      "Epoch 940: train loss = 0.0017, val loss = 0.8111\n",
      "Epoch 941: train loss = 0.0015, val loss = 0.7983\n",
      "Epoch 942: train loss = 0.0016, val loss = 0.8155\n",
      "Epoch 943: train loss = 0.0021, val loss = 0.8044\n",
      "Epoch 944: train loss = 0.0023, val loss = 0.8261\n",
      "Epoch 945: train loss = 0.0022, val loss = 0.8487\n",
      "Epoch 946: train loss = 0.0028, val loss = 0.8372\n",
      "Epoch 947: train loss = 0.0027, val loss = 0.8224\n",
      "Epoch 948: train loss = 0.0025, val loss = 0.8385\n",
      "Epoch 949: train loss = 0.0026, val loss = 0.8238\n",
      "Epoch 950: train loss = 0.0031, val loss = 0.8362\n",
      "Epoch 951: train loss = 0.0041, val loss = 0.8369\n",
      "Epoch 952: train loss = 0.0040, val loss = 0.8689\n",
      "Epoch 953: train loss = 0.0044, val loss = 0.8921\n",
      "Epoch 954: train loss = 0.0033, val loss = 0.8428\n",
      "Epoch 955: train loss = 0.0028, val loss = 0.8888\n",
      "Epoch 956: train loss = 0.0035, val loss = 0.8187\n",
      "Epoch 957: train loss = 0.0026, val loss = 0.8404\n",
      "Epoch 958: train loss = 0.0020, val loss = 0.8252\n",
      "Epoch 959: train loss = 0.0018, val loss = 0.8348\n",
      "Epoch 960: train loss = 0.0018, val loss = 0.8112\n",
      "Epoch 961: train loss = 0.0034, val loss = 0.8308\n",
      "Epoch 962: train loss = 0.0028, val loss = 0.8376\n",
      "Epoch 963: train loss = 0.0023, val loss = 0.8172\n",
      "Epoch 964: train loss = 0.0021, val loss = 0.8245\n",
      "Epoch 965: train loss = 0.0016, val loss = 0.8172\n",
      "Epoch 966: train loss = 0.0014, val loss = 0.8306\n",
      "Epoch 967: train loss = 0.0022, val loss = 0.8427\n",
      "Epoch 968: train loss = 0.0029, val loss = 0.7932\n",
      "Epoch 969: train loss = 0.0035, val loss = 0.8554\n",
      "Epoch 970: train loss = 0.0038, val loss = 0.8314\n",
      "Epoch 971: train loss = 0.0030, val loss = 0.8396\n",
      "Epoch 972: train loss = 0.0028, val loss = 0.8553\n",
      "Epoch 973: train loss = 0.0025, val loss = 0.8225\n",
      "Epoch 974: train loss = 0.0029, val loss = 0.8666\n",
      "Epoch 975: train loss = 0.0029, val loss = 0.8445\n",
      "Epoch 976: train loss = 0.0030, val loss = 0.8498\n",
      "Epoch 977: train loss = 0.0030, val loss = 0.8245\n",
      "Epoch 978: train loss = 0.0032, val loss = 0.8383\n",
      "Epoch 979: train loss = 0.0024, val loss = 0.8203\n",
      "Epoch 980: train loss = 0.0021, val loss = 0.8220\n",
      "Epoch 981: train loss = 0.0024, val loss = 0.8379\n",
      "Epoch 982: train loss = 0.0019, val loss = 0.8047\n",
      "Epoch 983: train loss = 0.0017, val loss = 0.8452\n",
      "Epoch 984: train loss = 0.0016, val loss = 0.8318\n",
      "Epoch 985: train loss = 0.0012, val loss = 0.8327\n",
      "Epoch 986: train loss = 0.0011, val loss = 0.8253\n",
      "Epoch 987: train loss = 0.0007, val loss = 0.8369\n",
      "Epoch 988: train loss = 0.0006, val loss = 0.8356\n",
      "Epoch 989: train loss = 0.0004, val loss = 0.8168\n",
      "Epoch 990: train loss = 0.0003, val loss = 0.8310\n",
      "Epoch 991: train loss = 0.0004, val loss = 0.8240\n",
      "Epoch 992: train loss = 0.0003, val loss = 0.8300\n",
      "Epoch 993: train loss = 0.0002, val loss = 0.8240\n",
      "Epoch 994: train loss = 0.0002, val loss = 0.8276\n",
      "Epoch 995: train loss = 0.0002, val loss = 0.8268\n",
      "Epoch 996: train loss = 0.0002, val loss = 0.8286\n",
      "Epoch 997: train loss = 0.0002, val loss = 0.8262\n",
      "Epoch 998: train loss = 0.0002, val loss = 0.8278\n",
      "Epoch 999: train loss = 0.0002, val loss = 0.8272\n",
      "Epoch 1000: train loss = 0.0002, val loss = 0.8265\n"
     ]
    }
   ],
   "source": [
    "model = train_final_model(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12d89557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mood_predictions(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8862b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  predicted_mood\n",
      "0   AS14.01        6.772830\n",
      "1   AS14.02        6.537642\n",
      "2   AS14.03        7.273162\n",
      "3   AS14.05        5.775200\n",
      "4   AS14.06        6.167248\n",
      "5   AS14.07        4.836257\n",
      "6   AS14.08        7.125448\n",
      "7   AS14.09        5.926589\n",
      "8   AS14.12        6.407317\n",
      "9   AS14.13        7.590767\n",
      "10  AS14.14        7.284591\n",
      "11  AS14.15        6.683394\n",
      "12  AS14.16        6.206960\n",
      "13  AS14.17        6.255630\n",
      "14  AS14.19        6.459166\n",
      "15  AS14.20        6.737356\n",
      "16  AS14.23        6.770637\n",
      "17  AS14.24        5.297299\n",
      "18  AS14.25        6.937524\n",
      "19  AS14.26        6.102585\n",
      "20  AS14.27        6.251029\n",
      "21  AS14.28        7.380898\n",
      "22  AS14.29        6.143393\n",
      "23  AS14.30        5.971177\n",
      "24  AS14.31        7.070444\n",
      "25  AS14.32        7.170526\n",
      "26  AS14.33        6.215861\n"
     ]
    }
   ],
   "source": [
    "# Run predictions on test_df\n",
    "test_predictions = predict(model, pred_df, id_map, device)\n",
    "\n",
    "# Attach predictions to test_df\n",
    "test_df_with_preds = pred_df.copy()\n",
    "test_df_with_preds['predicted_mood'] = test_predictions\n",
    "\n",
    "# Optional: save to CSV or examine\n",
    "print(test_df_with_preds[['id', 'predicted_mood']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
